@inproceedings{Kusneniwar2024harvnet,
author = {Kusneniwar, Hrishikesh Govindrao and Sen, Sougata and Hester, Josiah},
title = {Poster: HarvNet: Battery-Free Device Network Simulator},
year = {2024},
isbn = {9798400705816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643832.3661444},
doi = {10.1145/3643832.3661444},
abstract = {Ubiquitous sensing technologies, leveraging a network of interconnected sensors and devices, offer multifaceted benefits to society. However, the use of batteries has persistently posed a challenge to their advancement. In recent years, researchers have explored establishing communication between battery-free nodes. The primary objective of this work is to expedite the testing of algorithms for multiple battery-free interconnected nodes by isolating the algorithm from the underlying hardware. Isolating the hardware allows faster tuning of algorithms, and enables testing on a large scale. We developed a novel python-based simulation framework, HarvNet. Simulations using real-world power traces demonstrated a success rate of 81\% in establishing connections between nodes which closely emulates the success rate achieved using hardware.},
booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
pages = {732–733},
numpages = {2},
keywords = {ubiquitous computing, battery-free device networks},
location = {Minato-ku, Tokyo, Japan},
series = {MOBISYS '24}
}



@inproceedings{Schleter2024brushing,
author = {Schleter, Blake and Avdonina, Marina and Adhikary, Rishiraj and Jaisinghani, Dheryta and Sen, Sougata},
title = {Poster: An Automated Method to Detect Tooth Brushing Activity with Smartwatch Sensors},
year = {2024},
isbn = {9798400705816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643832.3661417},
doi = {10.1145/3643832.3661417},
abstract = {Oral diseases affect an estimated 3.5 billion people globally, posing significant health challenges. According to the World Health Organization (WHO), adopting self-care practices and maintaining personal oral hygiene can substantially mitigate the prevalence of dental caries. While smartwatches have previously been utilized to track activities of daily living (ADL), their widespread availability has yet to be harnessed for accurately identifying tooth brushing activity among other common ADL. In this Work in Progress (WIP), we demonstrate how motion sensors integrated into smartwatches can effectively distinguish tooth brushing from seven other very similar ADL. We present our initial results that show a promising 94\% accuracy with 84\% sensitivity.},
booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
pages = {676–677},
    type={Workshop},
numpages = {2},
keywords = {toothbrushing, machine learning, activity recognition},
location = {Minato-ku, Tokyo, Japan},
series = {MOBISYS '24}
}


@inproceedings{Ghosh2024towards,
author = {Ghosh, Surjya and Mandi, Salma and Sen, Sougata and Mitra, Bivas and De, Pradipta},
title = {Towards Estimating Missing Emotion Self-reports Leveraging User Similarity: A Multi-task Learning Approach},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642833},
doi = {10.1145/3613904.3642833},
abstract = {The Experience Sampling Method (ESM) is widely used to collect emotion self-reports to train machine learning models for emotion inference. However, as ESM studies are time-consuming and burdensome, participants often withdraw in between. This unplanned withdrawal compels the researchers to discard the dropout participants’ data, significantly impacting the quality and quantity of the self-reports. To address this problem, we leverage only the self-reporting similarity across participants (unlike prior works that apply different machine learning approaches on additional modalities) for missing self-report estimation. In specific, we propose a Multi-task Learning (MTL) framework, MUSE, that constructs the missing self-reports of the dropout participants. We evaluate MUSE in two in-the-wild studies (N1=24, N2=30) of 6-week and 8-week duration, during which the participants reported four emotions (happy, sad, stressed, relaxed) using a smartphone application. The evaluation reveals that MUSE estimates the missing emotion self-reports with an average AUCROC of 84\% (Study I) and 82\% (Study II). A follow-up evaluation of MUSE for an emotion inference (downstream) task reveals no significant difference in emotion inference performance when estimated self-reports are used. These findings underscore the utility of MUSE in estimating missing self-reports in ESM studies and the applicability of MUSE for downstream tasks (e.g., emotion inference).},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {823},
  type={Conference},
numpages = {19},
keywords = {Emotion self-report, Experience Sampling Method (ESM), Multi-task learning},
location = {Honolulu, HI, USA},
series = {CHI '24}
}



@INPROCEEDINGS{Kusneniwar2024sonicglass,
  author={Kusneniwar, Hrishikesh Govindrao and Ghosh, Surjya and Sen, Sougata},
  booktitle={2024 16th International Conference on COMmunication Systems & NETworkS (COMSNETS)}, 
  title={SonicGlass: An Obstacle Detection and Navigation System Using Smartglass-Based Ultrasonic Sensors}, 
  year={2024},
  volume={},
  number={},
  pages={603-607},
      type={Workshop},
        series={Comsnets workshop},
  keywords={Three-dimensional displays;Navigation;Microcontrollers;Visual impairment;Sensor systems;Real-time systems;Sensors;smartglass;Accessibility;Indoor Navigation;Wearable Sensing;Obstacle Detection},
  doi={10.1109/COMSNETS59351.2024.10427277}
  }



@INPROCEEDINGS{Pinge2024mtanaaw,
  author={Pinge, Anuja and Jaisinghani, Dheryta and Ghosh, Surjya and Challa, Aditya and Sen, Sougata},
  booktitle={2024 16th International Conference on COMmunication Systems & NETworkS (COMSNETS)}, 
  title={mTanaaw: A System for Assessment and Analysis of Mental Health with Wearables}, 
  year={2024},
  volume={},
  number={},
  pages={105-110},
    type={Workshop},
      series={Comsnets workshop},
  keywords={Scalability;Pipelines;Mental health;Data collection;Wearable devices;Biomedical monitoring;Monitoring;Wearable Technology;Affective Computing},
  doi={10.1109/COMSNETS59351.2024.10427432}}



@article{Mamish2024nir,
author = {Mamish, John and Alharbi, Rawan and Sen, Sougata and Holla, Shashank and Kamath, Panchami and Sangar, Yaman and Alshurafa, Nabil and Hester, Josiah},
title = {NIR-sighted: A Programmable Streaming Architecture for Low-Energy Human-Centric Vision Applications},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1539-9087},
url = {https://doi.org/10.1145/3672076},
doi = {10.1145/3672076},
abstract = {Human studies often rely on wearable lifelogging cameras that capture videos of individuals and their surroundings to aid in visual confirmation or recollection of daily activities like eating, drinking and smoking. However, this may include private or sensitive information that may cause some users to refrain from using such monitoring devices. Also, short battery lifetime and large form factors reduce applicability for long-term capture of human activity. Solving this triad of interconnected problems is challenging due to wearable embedded systems’ energy, memory and computing constraints. Inspired by this critical use case and the unique design problem, we developed NIR-sighted, an architecture for wearable video cameras which navigates this design space via three key ideas: i)Reduce storage and enhance privacy by discarding masked pixels and frames. ii) Enable programmers to generate effective masks with low computational overhead. iii) Enable the use of small MCUs by moving masking and compression off-chip. Combined together in an end-to-end system, NIR-sighted’s masking capabilities and off-chip compression hardware shrinks systems, stores less data, and enables programmer-defined obfuscation to yield privacy enhancement. The user’s privacy is enhanced significantly as nowhere in the pipeline is any part of the image stored before it is obfuscated. We design a wearable camera called NIR-sightedCam based on this architecture; it is compact and can record IR and grayscale video at 16 and 20+fps respectively for 26 hours nonstop (59 hours with IR disabled) at a fraction of comparable platforms power draw. NIR-sightedCam includes a low-power FPGA which implements our mJPEG compress/obfuscate hardware, Blindspot. We additionally show the potential for privacy-enhancing function and clinical utility via an in-lab eating study, validated by a nutritionist.},
  type={Journal},
  volume={},
  number={},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {jun}
}


@article{colvin2023p14,
  title={P14-012-23 Sociodemographic Predictors of Eating Patterns Associated With Higher Quality Diets},
  author={Colvin, Christopher and Kusneniwar, Hrishikesh and Makelarski, Jennifer and Sen, Sougata and Kalam, Faiza and Lin, Annie},
  journal={Current Developments in Nutrition},
  volume={7},
number={},
  type={Journal},
  doi = {10.1016/j.cdnut.2023.100626},
url = {https://www.sciencedirect.com/science/article/pii/S2475299123253445},
 year={2023},
  publisher={Elsevier}
}

@article{lin2023or09,
  title={OR09-03-23 Development of an Automated Smartphone App Feature To Accurately Estimate Food Portion Sizes},
  author={Lin, Annie and Agwomoh, Kevin and Colvin, Christopher and Xu, Qiuyang and Sen, Sougata and Tan, Gabrielle and Chen, Edward and Pedram, Mahdi and Alshurafa, Nabil},
  journal={Current Developments in Nutrition},
 volume = {7},
pages = {101331},
year = {2023},
number={},
issn = {2475-2991},
doi = {https://doi.org/10.1016/j.cdnut.2023.101331},
url = {https://www.sciencedirect.com/science/article/pii/S2475299123260357},
  type={Journal},
  publisher={Elsevier}
}

@INPROCEEDINGS{shahi2023detecting,
  author={Shahi, Soroush and Sen, Sougata and Pedram, Mahdi and Alharbi, Rawan and Gao, Yang and Katsaggelos, Aggelos K and Hester, Josiah and Alshurafa, Nabil},
  booktitle={2023 IEEE/ACM Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)}, 
  title={Detecting Eating and Social Presence with All Day Wearable RGB-T}, 
  year={2023},
  volume={},
  number={},
  pages={68-79},
  type={Conference},
  series={IEEE/ACM Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)},
  doi={10.1145/3580252.3586974}}


@article{prajwal2023towards,
author = {Prajwal, M. and Raj, Ayush and Sen, Sougata and Saha, Snehanshu and Ghosh, Surjya},
title = {Towards Efficient Emotion Self-Report Collection Using Human-AI Collaboration: A Case Study on Smartphone Keyboard Interaction},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
url = {https://doi.org/10.1145/3596269},
doi = {10.1145/3596269},
abstract = {Emotion-aware services are increasingly used in different applications such as gaming, mental health tracking, video conferencing, and online tutoring. The core of such services is usually a machine learning model that automatically infers its user's emotions based on different biological indicators (e.g., physiological signals and facial expressions). However, such machine learning models often require a large number of emotion annotations or ground truth labels, which are typically collected as manual self-reports by conducting long-term user studies, commonly known as Experience Sampling Method (ESM). Responding to repetitive ESM probes for self-reports is time-consuming and fatigue-inducing. The burden of repetitive self-report collection leads to users responding arbitrarily or dropping out from the studies, compromising the model performance. To counter this issue, we, in this paper, propose a Human-AI Collaborative Emotion self-report collection framework, HACE, that reduces the self-report collection effort significantly. HACE encompasses an active learner, bootstrapped with a few emotion self-reports (as seed samples), and enables the learner to query for only not-so-confident instances to retrain the learner to predict the emotion self-reports more efficiently. We evaluated the framework in a smartphone keyboard-based emotion self-report collection scenario by performing a 3-week in-the-wild study (N = 32). The evaluation of HACE on this dataset (≈11,000 typing sessions corresponding to more than 200 hours of typing data) demonstrates that it requires 46\% fewer self-reports than the baselines to train the emotion self-report detection model and yet outperforms the baselines with an average self-report detection F-score of 85\%. These findings demonstrate the possibility of adopting such a human-AI collaborative approach to reduce emotion self-report collection efforts.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {jun},
    type={Journal},
articleno = {68},
numpages = {23},
keywords = {ESM, Survey fatigue, Active learning, User engagement, Experience Sampling Method}
}

@inproceedings{pedram2023experiences,
author = {Pedram, Mahdi and Fernandes, Glenn and Romano, Christopher and Wei, Boyang and Sen, Sougata and Hester, Josiah and Alshurafa, Nabil},
title = {Experience: Barriers and Opportunities of Wearables for Eating Research},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3573841},
doi = {10.1145/3544549.3573841},
abstract = {Wearable devices have long held the potential to provide real-time objective measures of behavior. However, due to challenges in real-world deployment, these systems are rarely tested rigorously in free-living settings. To reduce this challenge for future researchers, in this paper, we describe our experience developing several generations of a multi-sensor, neck-worn eating-detection system that has been tested with 130 participants across multiple studies in both laboratory and free-living settings. We describe the challenges faced in the development and deployment of the system by (1)&nbsp;presenting example deployment details captured either by the sensing system or the ground truth collector and (2)&nbsp;using structured interviews and surveys with developers and stakeholders of the system, collecting qualitative data on their experience. We performed thematic analysis and provided detailed lessons learned explaining factors that impact the experience of building and deploying such a wearable in a free-living setting, reducing challenges for future researchers. We believe that our experience will help future researchers develop successful mobile health (mHealth) systems that translate into reliable free-living deployments.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {383},
numpages = {8},
type={Conference},
keywords = {wearable sensors, eating detection, Case study},
location = {Hamburg, Germany},
series = {CHI EA '23}
}


@article{alharbi2022smokemon,
author = {Alharbi, Rawan and Shahi, Soroush and Cruz, Stefany and Li, Lingfeng and Sen, Sougata and Pedram, Mahdi and Romano, Christopher and Hester, Josiah and Katsaggelos, Aggelos K. and Alshurafa, Nabil},
title = {SmokeMon: Unobtrusive Extraction of Smoking Topography Using Wearable Energy-Efficient Thermal},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569460},
doi = {10.1145/3569460},
abstract = {Smoking is the leading cause of preventable death worldwide. Cigarette smoke includes thousands of chemicals that are harmful and cause tobacco-related diseases. To date, the causality between human exposure to specific compounds and the harmful effects is unknown. A first step in closing the gap in knowledge has been measuring smoking topography, or how the smoker smokes the cigarette (puffs, puff volume, and duration). However, current gold-standard approaches to smoking topography involve expensive, bulky, and obtrusive sensor devices, creating unnatural smoking behavior and preventing their potential for real-time interventions in the wild. Although motion-based wearable sensors and their corresponding machine-learned models have shown promise in unobtrusively tracking smoking gestures, they are notorious for confounding smoking with other similar hand-to-mouth gestures such as eating and drinking. In this paper, we present SmokeMon, a chest-worn thermal-sensing wearable system that can capture spatial, temporal, and thermal information around the wearer and cigarette all day to unobtrusively and passively detect smoking events. We also developed a deep learning--based framework to extract puffs and smoking topography. We evaluate SmokeMon in both controlled and free-living experiments with a total of 19 participants, more than 110 hours of data, and 115 smoking sessions achieving an F1-score of 0.9 for puff detection in the laboratory and 0.8 in the wild. By providing SmokeMon as an open platform, we provide measurement of smoking topography in free-living settings to enable testing of smoking topography in the real world, with potential to facilitate timely smoking cessation interventions.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {jan},
    type={Journal},
articleno = {155},
numpages = {25},
type={Journal},
keywords = {HAR, Smoking, Thermal, Wearable}
}

@INPROCEEDINGS{mathkar2023PiDiBuddy,
  author={Mathkar, Saumya and Karsh, Prakhar and Baluja, Udit and Ghosh, Surjya and Sen, Sougata and Naik, Vinayak},
  booktitle={2023 15th International Conference on COMmunication Systems & NETworkS (COMSNETS)}, 
  title={A Smartphone-based Application to Detect Parkinson's Disease Using Audio}, 
  year={2023},
  volume={},
  number={},
  pages={177-179},
  series={Comsnets workshop},
  type={Workshop},
  doi={10.1109/COMSNETS56262.2023.10041413}}


@inproceedings{hari2022affectpro,
  author = {Hari, Satchit and Ajay, N and Sarcar, Sayan and Sen, Sougata and Ghosh, Surjya},
title = {AffectPro: Towards Constructing Affective Profile Combining Smartphone Typing Interaction and Emotion Self-Reporting Pattern},
year = {2022},
isbn = {9781450393904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3536221.3556603},
doi = {10.1145/3536221.3556603},
abstract = {The ubiquity of smartphones and the widespread usage of text entry by soft keyboard in different instant messaging applications (e.g., WhatsApp, FB messenger) have opened the possibilities of inferring emotions from longitudinal typing data. To build this emotion inference engine, we apply machine learning models on features extracted from user’s typing patterns (not content). However, one major challenge encountered while developing the emotion inference model is the requirement of individual training data as typing patterns are often person-specific. In this paper, we investigate the possibility of combining typing pattern with emotion self-reporting to identify a group of similar users so that the training data among these users can be shared to fulfill the requirement of personalized dataset. We develop a framework AffectPro, which quantifies the typing interaction behavior (e.g., typing speed, error rate) and self-reporting pattern (e.g., emotion state transition probability) to construct the affective profiles of users. We evaluated AffectPro in a 6-week in-the-wild study involving 28 users, who used an Android application encompassing a custom keyboard to perform all their typing activities, and to report their instantaneous emotions. We extracted different typing signatures and self-report behavior details from the collected dataset (≈ 5000 typing sessions, ≈ 108 hours of typing data) to construct the affective profile of users. Our results demonstrate similarity across users in terms of typing signature, emotion self-reporting pattern, and a combination of both; which can be leveraged to share training data among similar users to overcome the challenges of personalized data collection.},
booktitle = {Proceedings of the 2022 International Conference on Multimodal Interaction},
pages = {217–223},
numpages = {7},
type={Conference},
keywords = {Emotion self-report, Affective profile, Smartphone typing, Emotion detection},
location = {Bengaluru, India},
series = {ICMI '22}
}



@article{lin2022prediction,
    author = {Lin, Annie and Cornely, Adrian and Kalam, Faiza and Sen, Sougata and Makelarski, Jennifer and Colvin, Christopher and Ward, Danielle and Mirsky, Grace},
    title = "{Prediction of Diet Quality Based on Day-Level Meal Pattern: A Preliminary Analysis Using Decision Tree Modeling}",
    journal = {Current Developments in Nutrition},
    volume = {6},
    number = {Supplement_1},
    pages = {417-417},
    year = {2022},
    month = {06},
    abstract = "{Previous studies have investigated if meal timing is associated with energy and macronutrient intake. However, few focus on the combination of food intake and meal timing and their association with diet quality. We use machine learning to examine how day-level meal patterns (food group intake, meal timing) predict diet quality among adults.We analyzed diet data from interviewer-administered 24-hour recalls from the NHANES 2015–2016 and 2017–2018 cycles (N = 9761). Fifteen food groups were examined: fruit, fruit juice, vegetables, whole grains, meats (red, cured, poultry, seafood), eggs, plant protein, dairy, oils, solid fats, added sugar, and alcohol. Proportion of intake for each food group per participant - relative to that participant's total daily intake of that food group - was included as input parameters for each meal (breakfast, lunch, dinner). Diet quality was computed using the Healthy Eating Index 2015 (HEI-2015); higher scores represented better diet quality. Cutoff threshold for a higher vs. lower quality diet was defined by the 75th percentile of HEI-2015 for the dataset (cutoff = 59.24). Decision tree modeling identified the inputs that contributed to the highest information gain and the optimal classification threshold for each input.On average, participants consumed 0.4± 0.8 cup equivalents of fruits and 0.6 ± 1.2 ounce equivalents of whole grains. These two food groups contributed most to the diet quality prediction model, which had a 78\\% classification accuracy for the dataset. Lower quality diets were associated with: a) \\&lt; 2\\% of both total fruit and whole grain intake at breakfast; b) \\&gt;2\\%of total fruit but \\&lt; 2\\% of total whole grain intake at breakfast; or c) \\&gt;2\\% of total whole grain intake at breakfast but \\&lt; 2\\% of total fruit intake at breakfast and lunch. Higher quality diets were associated with: a) \\&gt;2\\% of both total fruit and whole grain intake at breakfast or b) \\&lt; 2\\% of total fruit intake at breakfast but \\&gt; 2\\% of both total whole grain intake at breakfast and fruit intake at lunch. Food group intake at dinner was not a top predictor in the preliminary model.Preliminary analyses revealed that the timing of fruit and whole grain consumption are important predictors of diet quality. Future studies should test the preliminary model on additional datasets and should include snacking episodes in the analyses.None.}",
    issn = {2475-2991},
    type={Journal},
    doi = {10.1093/cdn/nzac055.006},
    url = {https://doi.org/10.1093/cdn/nzac055.006},
    eprint = {https://academic.oup.com/cdn/article-pdf/6/Supplement\_1/417/44041391/nzac055.006.pdf},
}





@inproceedings{shahi2022comorea,
author={Shahi, Soroush and Alharbi, Rawan and Gao, Yang and  Sen, Sougata and Katsaggelos, Aggelos and Hester, Josiah and Alshurafa, Nabil },
booktitle = {International Conference on Pervasive Computing and Communication Workshops},
type={Workshop},
title = {Impacts of Image Obfuscation on Fine-grained Activity Recognition in Egocentric Video},
year = {2022},
volume = {},
issn = {},
pages = {341-346},
keywords = {training; pervasive computing; location awareness; privacy; conferences; streaming media; activity recognition},
doi = {10.1109/PerComWorkshops53856.2022.9767447},
url = {https://doi.ieeecomputersociety.org/10.1109/PerComWorkshops53856.2022.9767447},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
series = {PerCom Workshops}  ,
month = {mar}
}


@inproceedings{adate2022hccs,
title={Detecting Screen Presence with Activity-oriented RGB Camera in Egocentric Videos},
author={Adate,Amit and Shahi , Soroush and Alharbi , Rawan and Sen, Sougata and Gao, Yang and Katsaggelos , Aggelos and Alshurafa, Nabil },
year={2022},
abstract={},
url={https://www.percom.org/},
booktitle = {International Conference on Pervasive Computing and Communication Workshops},
numpages = {},
type={Workshop},
series = {PerCom Workshops}  
}
  
}


@inproceedings{adithya2022ocean,
title={OCEAN: Towards Developing an Opportunistic Continuous Emotion Annotation Framework},
author={Adithya, Akhilesh and Tiwari,Snigdha and Sen, Sougata and Chakraborty, Sandip and Ghosh, Surjya},
year={2022},
abstract={},
url={https://www.percom.org/},
booktitle = {International Conference on Pervasive Computing and Communications},
numpages = {},
type={Workshop},
series = {PerCom WiP}  
}
  

@inproceedings{Alharbi2022actisight,
title={ActiSight: Wearer Foreground Extraction using a Practical RGB-Thermal Wearable},
author={Alharbi, Rawan and Sen, Sougata and Ng, Ada and Alshurafa, Nabil and Hester, Josiah},
year={2022},
abstract={},
url={https://www.percom.org/},
booktitle = {International Conference on Pervasive Computing and Communications},
pages = {9},
numpages = {},
type={Conference},
series = {PerCom}  
}


@inproceedings{Pinge2022Comparison,
title={A Comparative Study between ECG-based and PPG-based Heart Rate Monitors for Stress Detection},
author={Pinge, Anuja and Bandopadhayay, Soumyadip and Ghosh, Surjya and Sen, Sougata },
year={2022},
doi={https://dx.doi.org/10.1109/COMSNETS53615.2022.9668342},
abstract={Recent advances in the field of wearable sensing has promoted the emergence of many health tracking devices, including heart rate monitors. Heart rate monitors are commonly either chest-based or wrist-based. Currently, it is unclear whether there is a substantial difference in the performance of these different heart rate monitors. To determine the difference in the performance, in this paper, we compare two chest-worn heart rate monitors and one wrist-worn heart rate monitor. Our initial results indicate that there is substantial difference between the devices - the root mean square error between devices can be above 10 beats per minute. However, even though there is difference in performance of different heart rate monitors, yet each of these devices are capable of detecting stress (using an machine learning model) with a F1-score of above 0.8. In this paper, we also introduce the idea of formally verifying the rules obtained from the machine learning classifier; such formal verification will enable improving the explainability and confidence of the outcome of the machine learning models.},
booktitle = {International Conference on COMmunication Systems   NETworkS (COMSNETS)},
pages = {84-89},
numpages = {6},
type={Workshop},
series = {NetHealth}
}
  

@article{Sen2021VibeRing,
title = {VibeRing: Using vibrations from a smart ring as an out-of-band channel for sharing secret keys},
journal = {Pervasive and Mobile Computing},
pages = {101505},
year = {2021},
volume={},
number={},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2021.101505},
url = {https://www.sciencedirect.com/science/article/pii/S1574119221001309},
author = {Sen, Sougata and Kotz,David },
keywords = {Smart Ring, Vibration, Security, Wearables, IoT},
abstract = {Many Internet of Things (IoT) devices are capable of sensing their environment, communicating with other devices, and actuating on their environment. Some of these IoT devices, herein known as “smartThings”, collect meaningful information from raw data when they are in use and in physical contact with their user (e.g., a blood-glucose monitor); the smartThing’s wireless connectivity allows it to transfer that data to its user’s trusted device, such as a smartphone. However, an adversary could impersonate the user and bootstrap a communication channel with the smartThing, while the smartThing is being used by an oblivious legitimate user. To address this problem, in this paper, we investigate the use of vibration, generated by a smartRing, as an out-of-band communication channel to unobtrusively share a secret with a smartThing. This exchanged secret can be used to bootstrap a secure wireless channel over which the smartphone (or another trusted device) and the smartThing can communicate. We present the design, implementation, and evaluation of this system, which we call VibeRing. We describe the hardware and software details of the smartThing and smartRing. Through a user study we demonstrate that it is possible to share a secret with various objects quickly, accurately and securely as compared to several existing techniques. Overall, we successfully exchange a secret between a smartRing and various smartThings, at least 85.9% of the time. We show that VibeRing can perform this exchange at 12.5bits/second at a bit error rate of less than 2.5%. We also show that VibeRing is robust to the smartThing’s constituent material as well as the holding style. Finally, we demonstrate that a nearby adversary cannot decode or modify the message exchanged between the trusted devices.},
type={Journal}
}

@inproceedings{Karnavat2021exploring,
author = {Karnavat, Tejal and Singh Bhatia, Jaskaran and Ghosh, Surjya and Sen, Sougata},
title = {Exploring the challenges of using food journaling apps: A case-study with young adults},
year = {2021},
isbn = {},
url = {},
doi = {https://doi.org/10.1007/978-3-030-94822-1_4},
abstract = {Food journaling applications (e.g., MyFitnessPal) can aid in tracking food consumption, physical activities and the overall Quality of Life (QoL). Although these apps can improve self-consciousness, there are several challenges that prevent widespread usage of these apps in long term. We, in this paper, investigate the major challenges faced by the users (especially young adults) while using these apps. Towards this objective, we performed two user studies. In the first study, we performed a large-scale online crowd-sourced survey involving more than 150 participants who have experience with at least one food journaling app. While this study highlights the major challenges faced by the users of these apps, we performed a follow-up study to validate these findings in a more realistic setting. The second study involved 31 participants (in the age range of 22 to 27 years), who used the MyFitnessPal app continuously for up to 10 days to record their caloric input and output. We performed thematic analysis on the qualitative data of the exit interview, which highlighted a few themes, corroborating with the major challenges faced by the users in UI, search options (for food), serving size, and reminders while using these apps. We reflect on these findings to discuss a set of plausible avenues to increase the long-term and widespread usage of these applications.},
booktitle = {18th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {57-83},
numpages = {},
type={Conference},
series = {MobiQuitous}
}


@misc{deiana2021applications,
      title={Applications and Techniques for Fast Machine Learning in Science}, 
      author={Allison McCarn Deiana and Nhan Tran and Joshua Agar and Michaela Blott and Giuseppe Di Guglielmo and Javier Duarte and Philip Harris and Scott Hauck and Mia Liu and Mark S. Neubauer and Jennifer Ngadiuba and Seda Ogrenci-Memik and Maurizio Pierini and Thea Aarrestad and Steffen Bahr and Jurgen Becker and Anne-Sophie Berthold and Richard J. Bonventre and Tomas E. Muller Bravo and Markus Diefenthaler and Zhen Dong and Nick Fritzsche and Amir Gholami and Ekaterina Govorkova and Kyle J Hazelwood and Christian Herwig and Babar Khan and Sehoon Kim and Thomas Klijnsma and Yaling Liu and Kin Ho Lo and Tri Nguyen and Gianantonio Pezzullo and Seyedramin Rasoulinezhad and Ryan A. Rivera and Kate Scholberg and Justin Selig and Sougata Sen and Dmitri Strukov and William Tang and Savannah Thais and Kai Lukas Unger and Ricardo Vilalta and Belinavon Krosigk and Thomas K. Warburton and Maria Acosta Flechas and Anthony Aportela and Thomas Calvet and Leonardo Cristella and Daniel Diaz and Caterina Doglioni and Maria Domenica Galati and Elham E Khoda and Farah Fahim and Davide Giri and Benjamin Hawks and Duc Hoang and Burt Holzman and Shih-Chieh Hsu and Sergo Jindariani and Iris Johnson and Raghav Kansal and Ryan Kastner and Erik Katsavounidis and Jeffrey Krupa and Pan Li and Sandeep Madireddy and Ethan Marx and Patrick McCormack and Andres Meza and Jovan Mitrevski and Mohammed Attia Mohammed and Farouk Mokhtar and Eric Moreno and Srishti Nagu and Rohin Narayan and Noah Palladino and Zhiqiang Que and Sang Eon Park and Subramanian Ramamoorthy and Dylan Rankin and Simon Rothman and Ashish Sharma and Sioni Summers and Pietro Vischia and Jean-Roch Vlimant and Olivia Weng},
      year={2021},
      eprint={2110.13041},
      archivePrefix={arXiv},
      type={Journal},
      primaryClass={cs.LG}
}


@inproceedings{Alharbi2021heatsight,
author = {Alharbi, Rawan and Feng, Chunlin and Sen, Sougata and Jain, Jayalakshmi and Hester, Josiah and Alshurafa, Nabil},
title = {HeatSight: Wearable Low-Power Omni Thermal Sensing},
year = {2021},
isbn = {9781450384629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460421.3478811},
doi = {10.1145/3460421.3478811},
abstract = { Thermal information surrounding a person is a rich source for understanding and identifying personal activities. Different daily activities naturally emit distinct thermal signatures from both the human body and surrounding objects; these signatures exhibit both spatial and temporal components as objects move and thermal energy dissipates, for example, when drinking a cold beverage or smoking a cigarette. We present HeatSight, a wearable system that captures the thermal environment of the wearer and uses machine learning to infer human activity from thermal, spatial, and temporal information in that environment. We achieve this by embedding five low-power thermal sensors in a pentahedron configuration which captures a wide view of the wearer’s body and the objects they interact with. We also design a battery life-saving mechanism that selectively powers only those sensors necessary for detection. With HeatSight, we unlock thermal as an egocentric modality for future interaction research.},
booktitle = {2021 International Symposium on Wearable Computers},
pages = {108–112},
numpages = {5},
keywords = {low-power, thermal sensing, human activity detection, wearable},
location = {Virtual, USA},
type={Conference},
note={[Best Presentation Award at ISWC'21]},
series = {ISWC}
}

@InProceedings{peters2021via,
  author =        {Peters,Travis and Pierson, Timothy J. and Sen, Sougata and Camacho,Jos{\'{e}} and Kotz,David },
  title =         {Recurring Verification of Interaction Authenticity Within Bluetooth Networks},
  booktitle =     {Proceedings of the ACM Conference on Security and Privacy in Wireless and Mobile Networks},
  year =          {2021},
  month =         {June},
  series={WiSec},
  copyright =     {ACM},
  DOI =           {10.1145/3448300.3468287},
  URL =           {https://www.cs.dartmouth.edu/~kotz/research/peters-via/index.html},
  abstract =      {Although user authentication has been well explored, device-to-device authentication -- specifically in Bluetooth networks -- has not seen the same attention. We propose Verification of Interaction Authenticity (VIA) -- a recurring authentication scheme based on evaluating characteristics of the communications (interactions) between devices. We adapt techniques from wireless traffic analysis and intrusion detection systems to develop behavioral models that capture typical, authentic device interactions (behavior); these models enable recurring verification of device behavior. To evaluate our approach we produced a new dataset consisting of more than 300 Bluetooth network traces collected from 20 Bluetooth-enabled smart-health and smart-home devices. In our evaluation, we found that devices can be correctly verified at a variety of granularities, achieving an F1-score of 0.86 or better in most cases.},
  type={Conference}
}

@article{Mishra2020Evaluating,
author = {Mishra, Varun and Sen, Sougata and Chen, Grace and Hao, Tian and Rogers, Jeffrey and Chen, Ching-Hua and Kotz, David},
title = {Evaluating the Reproducibility of Physiological Stress Detection Models},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
url = {https://doi.org/10.1145/3432220},
doi = {10.1145/3432220},
abstract = {Recent advances in wearable sensor technologies have led to a variety of approaches for detecting physiological stress. Even with over a decade of research in the domain, there still exist many significant challenges, including a near-total lack of reproducibility across studies. Researchers often use some physiological sensors (custom-made or off-the-shelf), conduct a study to collect data, and build machine-learning models to detect stress. There is little effort to test the applicability of the model with similar physiological data collected from different devices, or the efficacy of the model on data collected from different studies, populations, or demographics.This paper takes the first step towards testing reproducibility and validity of methods and machine-learning models for stress detection. To this end, we analyzed data from 90 participants, from four independent controlled studies, using two different types of sensors, with different study protocols and research goals. We started by evaluating the performance of models built using data from one study and tested on data from other studies. Next, we evaluated new methods to improve the performance of stress-detection models and found that our methods led to a consistent increase in performance across all studies, irrespective of the device type, sensor type, or the type of stressor. Finally, we developed and evaluated a clustering approach to determine the stressed/not-stressed classification when applying models on data from different studies, and found that our approach performed better than selecting a threshold based on training data. This paper's thorough exploration of reproducibility in a controlled environment provides a critical foundation for deeper study of such methods, and is a prerequisite for tackling reproducibility in free-living conditions.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {Dec},
articleno = {147},
numpages = {29},
type={Journal},
keywords = {Stress detection, mobile health (mHealth), mental health, wearable sensing}
}


@inproceedings{Sen2020Battery,
author = {Sen, Sougata and Lee, Sunghoon Ivan and Jackson, Robert and Wang, Rui and Alshurafa, Nabil and Hester, Josiah and Gummeson, Jeremy},
title = {Towards Battery-Free Body Sensor Networks},
year = {2020},
isbn = {9781450381291},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417308.3430275},
doi = {10.1145/3417308.3430275},
abstract = {Wearable devices traditionally rely on batteries as the primary source of energy for operation. Batteries are often rigid, bulky, heavy, and require constant recharging, consequently hampering the development of novel device applications. This paper describes a new vision for Body Sensor Networks (BSNs); an interconnection of tiny, flexible, battery-free, cooperative, and programmable wearables via the concept of Intra-Body Power Transfer and Communication (IBPTC), which uses the human body as a medium to exchange energy and data. These wearable devices can receive energy from central, on-body power sources, and coordinate to support whole-system operation and programmer-defined sensing tasks. Of course, this vision entails significant challenges; notably in developing robust hardware and software for energy and information exchange across the body channel, enabling power failure resiliency and timely coordinated task execution. In this paper, we describe a roadmap of systems and tools towards the ultimate vision of battery-free BSNs that has the potential to transform current architectures and designs of BSNs, enabling innovative applications that would otherwise be impossible with on-device batteries.},
booktitle = {Proceedings of the 8th International Workshop on Energy Harvesting and Energy-Neutral Sensing Systems},
pages = {79–81},
numpages = {3},
location = {Virtual Event, Japan},
type={Workshop},
series = {ENSsys '20}
}

@article{Sen2020Annapurna,
abstract = {Maintaining a food journal can allow an individual to monitor eating habits, including unhealthy eating sessions, food items causing severe reactions, or portion size related information. However, manually maintaining a food journal can be burdensome. In this paper, we explore the vision of a pervasive, automated, completely unobtrusive, food journaling system using a commodity smartwatch. We present a prototype system — Annapurna— which is composed of three key components: (a) a smartwatch-based gesture recognizer that can robustly identify eating-specific gestures occurring anywhere, (b) a smartwatch-based image captor that obtains a small set of relevant images (containing views of the food being consumed) with a low energy overhead, and (c) a server-based image filtering engine that removes irrelevant uploaded images. Through lessons learnt from multiple user studies, we refine Annapurna progressively and show that our vision is indeed achievable: Annapurna can identify eating episodes and capture food images (involving a very wide diversity in food content, eating styles and environments) in over 95% of all free-living eating episodes.},
author = {Sen, Sougata and Subbaraju, Vigneshwaran and Misra, Archan and Balan, Rajesh and Lee, Youngki},
title = {{Annapurna: An automated smartwatch-based eating detection and food journaling system}},
doi={10.1016/j.pmcj.2020.101259},
journal = {Pervasive and Mobile Computing},
month = {October},
publisher = {Elsevier},
volume = {68},
year = {2020},
number={},
type={Journal}
}


@inproceedings{Zhang2020,
abstract = {Smartphones, with their ubiquity and plethora of embedded sensors enable on-the-go measurement. In this poster, we describe one novel measurement potential -- weight measurement -- by turning an everyday smartphone into a weighing scale. We describe VibroScale, our vibration-based approach to measuring weights of objects, that are small in size. Being able to objectively measure the weight of objects in free-living settings, without the burden of carrying a weighing scale has several possible use cases, particularly in weighing of small food items. We designed a smartphone app and regression algorithm that estimates the relative induced intensity of an object placed on the smartphone. We tested our proposed method on more than 50 fruits and other everyday objects of different sizes and weights. The results demonstrate that our smartphone-based method can measure the weight of fruits without relying on an actual weighing scale. Overall, we observed that VibroScale can measure one type of object with a mean absolute error of 12.4 grams. We believe that in future this approach can be generalized to estimate calories and measure weight of various types of objects.},
author = {Zhang, Shibo and Xu, Qiuyang and Sen, Sougata and Alshurafa, Nabil},
booktitle = {International Joint Conference on Pervasive and Ubiquitous Computing and International Symposium on Wearable Computers},
doi = {10.1145/3410530.3414397},
isbn = {978-1-4503-8076-8/20/09},
keywords = {smartphone, weighing scale, measurement, vibration, accelerometer},
month = {sep},
publisher = {Association for Computing Machinery, Inc},
series = {UbiComp/ISWC Adjunct},
title = {VibroScale: Turning Your Smartphone into a Weighing Scale},
year = {2020},
type={Poster},
note={[Best Poster Award]}
}

@InProceedings{Sen2020Vibering,
  author =        {Sen, Sougata and Kotz, David},
  title =         {VibeRing: Using vibrations from a smart ring as an out-of-band channel for sharing secret keys},
  booktitle =     {Proceedings of the International Conference on the Internet of Things},
  series= {IoT},
  year =          2020,
  month =         {October},
  copyright =     {the authors},
  doi =          {10.1145/3410992.3410995},
  type={Conference},
  abstract =      {With the rapid growth in the number of IoT devices that have wireless communication capabilities, and sensitive information collection capabilities, it is becoming increasingly necessary to ensure that these devices communicate securely with only authorized devices. A major requirement of this secure communication is to ensure that both the devices share a \emph{secret}, which can be used for secure pairing and encrypted communication. Manually imparting this secret to these devices becomes an unnecessary overhead, especially when the device interaction is transient. In this paper, we empirically investigate the possibility of using an out-of-band communication channel -- vibration, generated by a custom smart ring, to share a secret with a smart IoT device. This exchanged secret can be used to bootstrap a secure wireless channel over which the devices can communicate. We believe that in future IoT devices can use such a technique to seamlessly connect with authorized devices with minimal user interaction overhead. In this paper, we specifically investigate (a) the feasibility of using vibration generated by a custom wearable for communication, (b) the effect of various parameters on this communication channel, and (c) the possibility of information manipulation by an adversary or information leakage to an adversary. For this investigation, we conducted a controlled study as well as a user study with 12 participants. In the controlled study, we could successfully share messages through vibrations with a bit error rate of less than 2.5\%. Additionally, through the user study we demonstrate that it is possible to share messages with various types of objects accurately, quickly and securely as compared to several existing techniques. Overall, we find that in the best case we can exchange 85.9\% messages successfully with a smart device.},
  note={[Nominated as Candidate for Best Paper Award]}
}


@InProceedings{Bi2020,
author={Bi, Shengjie and Lu, Yiyang and Tobias, Nicole and Ryan, Ella and Masterson, Travis and Sen, Sougata and Halter, Ryan and Sorber, Jacob and Gilbert-Diamond, Diane and Kotz, David},
  title =         {Measuring children's eating behavior with a wearable device},
  booktitle =     {International Conference on Healthcare Informatics},
  series={ICHI},
  year =          2020,
  month =         {December},
  publisher =     {IEEE},
  copyright =     {IEEE},
  doi =          {},
  type={Conference},
  abstract =      {Poor eating habits in children and teenagers can lead to obesity, eating disorders, or life-threatening health problems. Although researchers have studied children's eating behavior for decades, the research community has had limited technology to support the observation and measurement of fine-grained details of a child's eating behavior. In this paper, we present the feasibility of adapting the Auracle, an existing research-grade earpiece designed to automatically and unobtrusively recognize eating behavior in adults, for measuring children's eating behavior. We identified and addressed several challenges pertaining to monitoring eating behavior in children, paying particular attention to device fit and comfort. We also improved the accuracy and robustness of the eating-activity detection algorithms. We used this improved prototype in a lab study with a sample of 10 children for 60 total sessions and collected 22.3 hours of data in both meal and snack scenarios. Overall, we achieved an accuracy exceeding 85.0% and an F1 score exceeding 84.2% for eating detection with a 3-second resolution, and a 95.5% accuracy and a 95.7% F1 score for eating detection with a 1-minute resolution.},
}


@article{Zhang2019,
abstract = {We present the design, implementation, and evaluation of a multi-sensor low-power necklace 'NeckSense' for automatically and unobtrusively capturing fine-grained information about an individual's eating activity and eating episodes, across an entire waking-day in a naturalistic setting. The NeckSense fuses and classifies the proximity of the necklace from the chin, the ambient light, the Lean Forward Angle, and the energy signals to determine chewing sequences, a building block of the eating activity. It then clusters the identified chewing sequences to determine eating episodes. We tested NeckSense with 11 obese and 9 non-obese participants across two studies, where we collected more than 470 hours of data in naturalistic setting. Our result demonstrates that NeckSense enables reliable eating-detection for an entire waking-day, even in free-living environments. Overall, our system achieves an F1-score of 81.6{\%} in detecting eating episodes in an exploratory study. Moreover, our system can achieve a F1-score of 77.1{\%} for episodes even in an all-day-around free-living setting. With more than 15.8 hours of battery-life NeckSense will allow researchers and dietitians to better understand natural chewing and eating behaviors, and also enable real-time interventions.},
author = {Zhang, Shibo and Zhao, Yuqi and Nguyen, Dzung Tri and Xu, Runsheng and Sen, Sougata and Hester, Josiah and Alshurafa, Nabil},
title = {{NeckSense: A Multi-Sensor Necklace for Detecting Eating Activities in Free-Living Conditions}},
doi={10.1145/3397313},
journal = {In Interactive, Mobile, Wearable and Ubiquitous Technologies},
month = {June},
number = {4},
articleno = {111},
publisher = {Association for Computing Machinery (ACM)},
volume = {37},
year = {2020},
note={[Best Presentation Runner-up at UbiComp/ISWC'20]},
type={Journal}
}
@inproceedings{Sen2019,
abstract = {With the rapid growth in the number of Internet of Things (IoT) devices with wireless communication capabilities, and sensitive information collection capabilities, it is becoming increasingly necessary to ensure that these devices communicate securely with only authorized devices. A major requirement of this secure communication is to ensure that both the devices share a secret, which can be used for secure pairing and encrypted communication. Manually imparting this secret to these devices becomes an unnecessary overhead, especially when the device interaction is transient. In this work, we empirically investigate the possibility of using an out-of-band communication channel – vibration, generated by a custom smartRing – to share a secret with a compatible IoT device. Through a user study with 12 participants we show that in the best case we can exchange 85.9{\%} messages successfully. Our technique demonstrates the possibility of sharing messages accurately, quickly and securely as compared to several existing techniques.},
author = {Sen, Sougata and Mishra, Varun and Kotz, David},
booktitle = {International Joint Conference on Pervasive and Ubiquitous Computing and International Symposium on Wearable Computers},
doi = {10.1145/3341162.3343818},
isbn = {9781450368698},
keywords = {IoT,Security,SmartRing,Vibration,Wearables},
month = {sep},
pages = {198--201},
publisher = {Association for Computing Machinery, Inc},
series = {UbiComp/ISWC Adjunct},
title = {{Using Vibrations from a SmartRing as an Out-of-band Channel for Sharing Secret Keys}},
year = {2019},
type={Poster}
}

@article{Mishra2019,
abstract = {Timely detection of an individual?s stress level has the potential to improve stress management, thereby reducing the risk of adverse health consequences that may arise due to mismanagement of stress. Recent advances in wearable sensing have resulted in multiple approaches to detect and monitor stress with varying levels of accuracy. The most accurate methods, however, rely on clinical-grade sensors to measure physiological signals; they are often bulky, custom-made, and expensive, hence limiting their adoption by researchers and the general public. In this paper, we explore the viability of commercially available off-the-shelf sensors for stress monitoring. The idea is to be able to use cheap, non-clinical sensors to capture physiological signals, and make inferences about the wearer?s stress level based on that data. We describe a system involving a popular off-the-shelf heart-rate monitor, the Polar H7; we evaluated our system with 26 participants in both a controlled lab setting with three well-validated stress-inducing stimuli and in free-living field conditions. Our analysis shows that using the off-the-shelf sensor alone, we were able to detect stressful events with an F1 score of 0.81 in the lab and 0.62 in the field, on par with clinical-grade sensors.},
author = {Mishra, Varun and Pope, Gunnar and Lord, Sarah and Lewia, Stephanie and Lowens, Byron and Caine, Kelly and Sen, Sougata and Halter, Ryan and Kotz, David},
journal = {ACM Transactions on Computing for Healthcare},
title = {{Continuous Detection of Physiological Stress with Commodity Hardware}},
volume = {1},
number={2},
articleno ={8},
DOI ={10.1145/3361562},
type={Journal},
year = {2020}
}
@inproceedings{Sen2018,
abstract = {In this paper, we present I 4 S, a system that identifies item interactions of customers in a retail store through sensor data fusion from smartwatches, smartphones and distributed BLE beacons. To identify these interactions, I 4 S builds a gesture-triggered pipeline that (a) detects the occurrence of ''item picks'', and (b) performs fine-grained localization of such pickup gestures. By analyzing data collected from 31 shoppers visiting a midsized stationary store, we show that we can identify person-independent picking gestures with a precision of over 88{\%}, and identify the rack from where the pick occurred with 91{\%}+ precision (for popular racks).},
author = {Sen, Sougata and Misra, Archan and Subbaraju, Vigneshwaran and Grover, Karan and Radhakrishnan, Meera and Balan, Rajesh K. and Lee, Youngki},
booktitle = {International Symposium on Wearable Computers},
doi = {10.1145/3267242.3267259},
file = {:C$\backslash$:/Users/Sougata/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sen et al. - 2018 - I 4 S Capturing shopper's in-store interactions.pdf:pdf},
isbn = {9781450359672},
issn = {15504816},
month = {oct},
pages = {156--159},
publisher = {Association for Computing Machinery},
series = {ISWC},
title = {{I4S: Capturing shopper's in-store interactions}},
type={Conference},
year = {2018}
}
@inproceedings{Radhakrishnan2018,
abstract = {We espouse the vision of a smart object/campus architecture where sensors attached to smart objects use BLE as communication interface, and where smartphones act as opportunistic relays to transfer the data. We explore the feasibility of the vision with real-world Wi-Fi based location traces from our university campus. Our feasibility studies establish that redundancy exists in user movement within the indoor spaces, and that this redundancy can be exploited for collecting sensor data in an opportunistic, yet fair manner. We develop a couple of alternative heuristics that address the BLE energy asymmetry challenge by intelligently duty-cycling the scanning actions of individual devices. We evaluate the efficacy and tradeoffs of the proposed approaches by simulation experiments with real-world location traces.},
author = {Radhakrishnan, Meera and Sen, Sougata and Misra, Archan and Lee, Youngki and Balan, Rajesh Krishna},
booktitle = {International Conference on Communication Systems and Networks},
doi = {10.1109/COMSNETS.2018.8328213},
isbn = {9781538611821},
month = {mar},
publisher = {IEEE},
series = {COMSNETS},
title = {{Smart monitoring via participatory BLE relaying}},
type={Conference},
year = {2018}
}
@inproceedings{Mishra2018,
abstract = {Timely detection of an individual's stress level has the potential to expedite and improve stress management, thereby reducing the risk of adverse health consequences that may arise due to unawareness or mismanagement of stress. Recent advances in wearable sensing have resulted in multiple approaches to detect and monitor stress with varying levels of accuracy. The most accurate methods, however, rely on clinical grade sensors strapped to the user. These sensors measure physiological signals of a person and are often bulky, custom-made, expensive, and/or in limited supply, hence limiting their large-scale adoption by researchers and the general public. In this paper, we explore the viability of commercially available off-the-shelf sensors for stress monitoring. The idea is to be able to use cheap, non-clinical sensors to capture physiological signals, and make inferences about the wearer's stress level based on that data. In this paper, we describe a system involving a popular off-the-shelf heart-rate monitor, the Polar H7; we evaluated our system in a lab setting with three well-validated stress-inducing stimuli with 26 participants. Our analysis shows that using the off-the-shelf sensor alone, we were able to detect stressful events with an F1 score of 0.81, on par with clinical-grade sensors.},
author = {Mishra, Varun and Pope, Gunnar and Lord, Sarah and Lewia, Stephanie and Lowens, Byron and Caine, Kelly and Sen, Sougata and Halter, Ryan and Kotz, David},
booktitle = {International Joint Conference on Pervasive and Ubiquitous Computing and International Symposium on Wearable Computers},
doi = {10.1145/3267305.3267538},
isbn = {9781450359665},
keywords = {Commodity wear-ables,Mental health,Mobile health (mHealth),Stress detection},
month = {oct},
pages = {1717--1728},
publisher = {ACM},
series = {UbiComp/ISWC Adjunct},
title = {{The case for a commodity hardware solution for stress detection}},
type={Workshop},
year = {2018}
}
@article{Bi2018,
abstract = {In this paper, we propose Auracle, a wearable earpiece that can automatically recognize eating behavior. More specifically, in free-living conditions, we can recognize when and for how long a person is eating. Using an off-the-shelf contact microphone placed behind the ear, Auracle captures the sound of a person chewing as it passes through the bone and tissue of the head. This audio data is then processed by a custom analog/digital circuit board. To ensure reliable (yet comfortable) contact between microphone and skin, all hardware components are incorporated into a 3D-printed behind-the-head framework. We collected field data with 14 participants for 32 hours in free-living conditions and additional eating data with 10 participants for 2 hours in a laboratory setting. We achieved accuracy exceeding 92.8{\%} and F1 score exceeding 77.5{\%} for eating detection. Moreover, Auracle successfully detected 20-24 eating episodes (depending on the metrics) out of 26 in free-living conditions. We demonstrate that our custom device could sense, process, and classify audio data in real time. Additionally, we estimate Auracle can last 28.1 hours with a 110 mAh battery while communicating its observations of eating behavior to a smartphone over Bluetooth.},
author = {Bi, Shengjie and Caine, Kelly and Halter, Ryan and Sorber, Jacob and Kotz, David and Wang, Tao and Tobias, Nicole and Nordrum, Josephine and Wang, Shang and Halvorsen, George and Sen, Sougata and Peterson, Ronald and Odame, Kofi},
doi = {10.1145/3264902},
file = {:C$\backslash$:/Users/Sougata/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bi et al. - 2018 - Auracle.pdf:pdf},
journal = {In Interactive, Mobile, Wearable and Ubiquitous Technologies},
month = {sep},
number = {3},
pages = {1--27},
publisher = {Association for Computing Machinery (ACM)},
title = {{Auracle: Detecting Eating Episodes with an Ear-mounted Sensor}},
volume = {2},
type={Journal},
year = {2018}
}
@inproceedings{Sen2018a,
abstract = {We describe the design and implementation of a smartwatch-based, completely unobtrusive, food journaling system, where the smartwatch helps to intelligently capture useful images of food that an individual consumes throughout the day. The overall system, called Annapurna, is based on three key components: (a) a smartwatch-based gesture recognizer to identify eating gestures, (b) a smartwatch-based image capturer that obtains a small set of relevant and useful images with a low energy overhead, and (c) a server-based image filtering engine that removes irrelevant uploaded images, and then catalogs them through a portal. Our primary challenge is to make the system robust to the huge diversity in natural eating habits and food choices. We show how we address this by an appropriate coupling between a smartwatch's camera sensor and inertial sensor-based tracking of eating gestures, thereby helping to capture multiple likely-to-be-useful images with low energy overhead. Through a series of real-world, in-the-wild studies, we demonstrate the end-to-end working of Annapurna, which captures useful images in over 95{\%} of all natural eating episodes.},
author = {Sen, Sougata and Subbaraju, Vigneshwaran and Misra, Archan and Balan, Rajesh and Lee, Youngki},
booktitle = {International Symposium on a World of Wireless, Mobile and Multimedia Networks},
doi = {10.1109/WoWMoM.2018.8449755},
isbn = {9781538647257},
month = {aug},
series = {WoWMoM},
title = {{Annapurna: Building a Real-World Smartwatch-Based Automated Food Journal}},
type={Conference},
year = {2018}
}
@inproceedings{Sen2017a,
abstract = {Due to numerous benefits, sensor-rich smartwatches and wrist-worn wearable devices are quickly gaining popularity. The popularity of these devices also raises privacy concerns. In this paper we explore one such privacy concern: the possibility of extracting the location of a user's touch-event on a smartphone, using the inertial sensor data of a smartwatch worn by the user on the same arm. This is a major concern not only because it might be possible for an attacker to extract private and sensitive information from the inputs provided but also because the attack mode utilises a device (smartwatch) that is distinct from the device being attacked (smartphone). Through a user study we find that such attacks are possible. Specifically, we can infer the user's entry pattern on a qwerty keyboard, with an error bound of ±2 neighboring keys, with 73.85{\%} accuracy. As a possible preventive mechanism, we also show that adding a little white noise to inertial sensor data can reduce the inference accuracy by almost 30{\%}, without affecting the accuracy of macro-gesture recognition.},
author = {Sen, Sougata and Grover, Karan and Subbaraju, Vigneshwaran and Misra, Archan},
booktitle = {International Conference on Pervasive Computing and Communications Workshops},
doi = {10.1109/PERCOMW.2017.7917646},
isbn = {9781509043385},
series = {PerCom Workshops},
title = {{Inferring smartphone keypress via smartwatch inertial sensing}},
type={Workshop},
year = {2017}
}
@article{Mo2017,
abstract = {In this paper, we reduce the energy overheads of continuous mobile sensing, specifically for the case of context-aware applications that are interested in collective context or events, i.e., events expressed as a set of complex predicates over sensor data from multiple smartphones. We propose a cloud-based query management and optimization framework, called CloQue, that can support thousands of such concurrent queries, executing over a large number of individual smartphones. Our central insight is that the context of different individuals {\&} groups often have significant correlation, and that this correlation can be learned through standard association rule mining on historical data. CloQue's exploits such correlation to reduce energy overheads via two key innovations: (i) dynamically reordering the order of predicate processing to preferentially select predicates with not just lower sensing cost and higher selectivity, but that maximally reduce the uncertainty about other context predicates; and (ii) intelligently propagating the query evaluation results to dynamically update the confidence values of other correlated context predicates. We present techniques for probabilistic processing of context queries (to save significant energy at the cost of a query fidelity loss) and for query partitioning (to scale CloQue to a large number of users while meeting latency bounds). An evaluation, using real cellphone traces from two different datasets, shows significant energy savings (between 30{\%} and 50{\%} compared with traditional short-circuit systems) with little loss in accuracy (5{\%} at most). In addition, we utilize parallel evaluation to reduce overall latency. The experiments show our approaches save up to 70{\%} latency.},
author = {Mo, Tianli and Lim, Lipyeow and Sen, Sougata and Misra, Archan and Balan, Rajesh Krishna and Lee, Youngki},
doi = {10.1016/j.pmcj.2016.12.005},
issn = {15741192},
journal = {Pervasive and Mobile Computing},
keywords = {Energy-efficient,Mobile sensing,Query evaluation},
number = {1},
pages = {257--274},
title = {{Cloud-based query evaluation for energy-efficient mobile sensing}},
volume = {38},
type={Journal},
year = {2017}
}
@inproceedings{Sen2017,
abstract = {In this paper, we describe the progressive design of the gesture recognition module of an automated food journaling system - Annapurna. Annapurna runs on a smartwatch and utilises data from the inertial sensors to first identify eating gestures, and then captures food images which are presented to the user in the form of a food journal. We detail the lessons we learnt from multiple in-the-wild studies, and show how eating recognizer is refined to tackle challenges such as (i) high gestural diversity, and (ii) non-eating activities with similar gestural signatures. Annapurna is finally robust (identifying eating across a wide diversity in food content, eating styles and environments) and accurate (false-positive and false-negative rates of 6.5{\%} and 3.3{\%} respectively).},
address = {New York, New York, USA},
author = {Sen, Sougata and Subbaraju, Vigneshwaran and Misra, Archan and Balan, Rajesh Krishna and Lee, Youngki},
booktitle = {International on Workshop on Physical Analytics},
doi = {10.1145/3092305.3092306},
isbn = {9781450349581},
pages = {7--12},
publisher = {ACM Press},
series = {WPA},
title = {{Experiences in Building a Real-World Eating Recogniser}},
url = {http://dl.acm.org/citation.cfm?doid=3092305.3092306},
type={Workshop},
year = {2017}
}
@inproceedings{Sen2016a,
abstract = {With the gradual increase in the number of individually owned mobile and wearable devices, as well as increase in the number of publicly available sensing devices, automatic {\&} unobtrusive monitoring of Activities of Daily Living (ADLs) is gradually becoming possible. In this work, we discuss about the important trade-off between energy, accuracy and non-personalization that has to be considered while building commercially successful ADL monitoring systems. We then describe two ADL monitoring systems that we have built which addresses technical challenges pertaining to building ADL monitoring systems. We also outline our proposed next steps in this research.},
author = {Sen, Sougata},
booktitle = {International Conference on Communication Systems and Networks},
doi = {10.1109/COMSNETS.2016.7439998},
isbn = {9781467396226},
series = {COMSNETS},
title = {{Pervasive physical analytics using multi-modal sensing}},
type={Workshop},
year = {2016}
}
@inproceedings{Radhakrishnan2016a,
abstract = {We espouse a vision of small data-based immersive retail analytics, where a combination of sensor data, from personal wearable-devices and store-deployed sensors {\&} IoT devices, is used to create real-Time, individualized services for in-store shoppers. Key challenges include (a) appropriate joint mining of sensor {\&} wearable data to capture a shopper's product-level interactions, and (b) judicious triggering of power-hungry wearable sensors (e.g., camera) to capture only relevant portions of a shopper's in-store activities. To explore the feasibility of our vision, we conducted experiments with 5 smartwatch-wearing users who interacted with objects placed on cupboard racks in our lab (to crudely mimic corresponding grocery store interactions). Initial results show significant promise: 94{\%} accuracy in identifying an item-picking gesture, 85{\%} accuracy in identifying the shelf-location from where the item was picked and 61{\%} accuracy in identifying the exact item picked (via analysis of the smartwatch camera data).},
author = {Radhakrishnan, Meera and Sen, Sougata and Subbaraju, Vigneshwaran and Misra, Archan and Balan, Rajesh Krishna},
booktitle = {International Conference on Communication Systems and Networks},
doi = {10.1109/COMSNETS.2016.7439946},
isbn = {9781467396226},
series = {COMSNETS},
title = {{IoT+Small Data: Transforming in-store shopping analytics {\&} services}},
type={Conference},
year = {2016}
}
@inproceedings{Sen2016b,
abstract = {Prolonged working hours are a primary cause of stress, work related injuries (e.g, RSIs), and work-life imbalance in employees at a workplace. As reported by some studies, taking timely breaks from continuous work not only reduces stress and exhaustion but also improves productivity, employee bonding, and camaraderie. Our goal is to build a system that automatically detects breaks thereby assisting in maintaining healthy work-break balance. In this paper, we focus on detecting foosball breaks of employees at a workplace using a smartwatch. We selected foosball as it is one of the most commonly played games at many workplaces in the United States. Since playing foosball involves wrist and hand movement, a wrist-worn device (e.g., a smartwatch), due to its position, has a clear advantage over a smartphone for detecting foosball activity. Our evaluation using data collected from real workplace shows that we can identify with more than 95{\%} accuracy whether a person is playing foosball or not. We also show that we can determine how long a foosball session lasted with an error of less than 3{\%} in the best case.},
author = {Sen, Sougata and Rachuri, Kiran K. and Mukherji, Abhishek and Misra, Archan},
booktitle = {International Conference on Pervasive Computing and Communication Workshops},
doi = {10.1109/PERCOMW.2016.7457165},
isbn = {9781509019410},
series = {PerCom Workshops},
title = {{Did you take a break today? Detecting playing foosball using your smartwatch}},
type={Workshop},
year = {2016}
}
@inproceedings{Sen2016,
author = {Sen, S. and Subbaraju, V. and Misra, A. and Lee, Y. and Balan, R.K.},
booktitle = {Annual International Conference on Mobile Systems, Applications, and Services},
doi = {10.1145/2938559.2938569},
isbn = {9781450344166},
series = {MobiSys Companion},
title = {{Demo: Smartwatch based food diary {\&} eating analytics}},
type={Demo},
year = {2016}
}
@inproceedings{Radhakrishnan2016,
author = {Radhakrishnan, M. and Eswaran, S. and Sen, S. and Subbaraju, V. and Misra, A. and Balan, R.K.},
booktitle = {International Conference on Mobile Systems, Applications, and Services},
doi = {10.1145/2938559.2938572},
isbn = {9781450344166},
series = {MobiSys Companion},
title = {{Demo: Smartwatch based shopping gesture recognition}},
type={Demo},
year = {2016}
}

@article{Mikusz2016,
abstract = {The 14th ACM International Conference on Mobile Systems, Applications, and Services (MobiSys 2016) spanned a range of themes and domains, from smart environments to security and privacy. The highlights presented here cover the keynotes, paper sessions, and first Asian Students Symposium on Emerging Technologies.},
author = {Mikusz, Mateusz and Clinch, Sarah and Sen, Sougata},
doi = {10.1109/MPRV.2016.62},
issn = {1536-1268},
journal = {Pervasive Computing},
keywords = {Internet of Things,Internet/Web technologies,MobiSys,mobile,networking,pervasive computing,security},
month = {oct},
number = {4},
pages = {85--88},
title = {{MobiSys 2016}},
url = {http://ieeexplore.ieee.org/document/7676201/},
volume = {15},
type={Journal},
year = {2016}
}
@inproceedings{Vigneshwaran2015,
abstract = {While mobile and wearable sensing can capture unique insights into fine-grained activities (such as gestures and limb-based actions) at an individual level, their energy overheads are still prohibitive enough to prevent them from being executed continuously. In this paper, we explore practical alternatives to addressing this challenge-by exploring how cheap infrastructure sensors or information sources (e.g., BLE beacons) can be harnessed with such mobile/wearable sensors to provide an effective solution that reduces energy consumption without sacrificing accuracy. The key idea is that many fine-grained activities that we desire to capture are specific to certain location, movement or background context: infrastructure sensors and information sources (e.g., BLE beacons) offer practical and cheap ways to identify such context. In this paper, we first explore how various infrastructure, mobile {\&} wearable sensors can be used to identify fine-grained location/movement context (e.g., transiting through a door). We then show, using a couple of illustrative examples (specifically, the detection of `switch pressing' before exiting a room and the identification of `water drinking' after approaching a water cooler) to show that such background context can be predicted, with sufficient accuracy, with sufficient lead time to enable a `triggered' model for mobile/wearable sensing of such microscopic, transient gestures and activities. Moreover, such `triggered' sensing also helps to improve the accuracy of such microscopic gesture recognition, by reducing the set of candidate activity labels. Empirical experiments show that we are able to identify 82.2{\%} of switch-pressing and 91.73{\%} of water-drinking activities in a campus lab setting, with a significant reduction in active sensing time (up to 92.9{\%} compared to continuous sensing).},
author = {Vigneshwaran, S. and Sen, Sougata and Misra, Archan and Chakraborti, Satyadip and Balan, Rajesh Krishna},
booktitle = {International Conference on Pervasive Computing and Communications},
doi = {10.1109/PERCOM.2015.7146513},
isbn = {978-1-4799-8033-8},
month = {mar},
pages = {87--94},
publisher = {IEEE},
series = {PerCom},
title = {{Using infrastructure-provided context filters for efficient fine-grained activity sensing}},
url = {http://ieeexplore.ieee.org/document/7146513/},
type={Conference},
year = {2015}
}
@inproceedings{Sen2015,
abstract = {We explore the use of gesture recognition on a wrist-worn smartwatch as an enabler of an automated eating activity (and diet monitoring) system. We show, using small-scale user studies, how it is possible to use the accelerometer and gyroscope data from a smartwatch to accurately separate eating episodes from similar non-eating activities, and to additionally identify the mode of eating (i.e., using a spoon, bare hands or chopsticks). Additionally, we investigate the likelihood of automatically triggering the smartwatch's camera to capture clear images of the food being consumed, for possible offline analysis to identify what (and how much) the user is eating. Our results show both the promise and challenges of this vision: while opportune moments for capturing such useful images almost always exist in an eating episode, significant further work is needed to both (a) correctly identify the appropriate instant when the camera should be triggered and (b) reliably identify the type of food via automated analyses of such images.},
author = {Sen, Sougata and Subbaraju, Vigneshwaran and Misra, Archan and Balan, Rajesh Krishna and Lee, Youngki},
booktitle = {International Conference on Pervasive Computing and Communication Workshops},
doi = {10.1109/PERCOMW.2015.7134103},
file = {:C$\backslash$:/Users/Sougata/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sen et al. - 2015 - The case for smartwatch-based diet monitoring.pdf:pdf},
isbn = {978-1-4799-8425-1},
month = {mar},
pages = {585--590},
publisher = {IEEE},
series = {PerCom Workshops},
title = {{The case for smartwatch-based diet monitoring}},
url = {http://ieeexplore.ieee.org/document/7134103/},
type={Workshop},
year = {2015},
note = {[Best Paper Award]}
}
@inproceedings{Sen2015b,
abstract = {With the availability of various publicly available and personal sensors, recording and profiling of activities of daily living (ADL) is becoming a reality. The sensors are omnipresent -in smartphones, smartwatches, and smartglasses and even in the environment around us in the form of peer smartphones or even infrastructure sensors such as bluetooth low energy beacons. However, there are various challenges pertaining to the sensor data processing, which makes creation of activities of daily life tracker challenging. In this work, we discuss about some of these challenges. We also discuss about some ADL tracking systems that we have developed and how we have addressed some of the challenges in building these systems. We further discuss about how various ADL trackers can be combined into a framework which can allow individuals to select a custom set of ADLs for self-tracking.},
author = {Sen, Sougata},
booktitle = {International Conference on Pervasive Computing and Communication Workshops},
doi = {10.1109/PERCOMW.2015.7134030},
file = {:C$\backslash$:/Users/Sougata/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sen - 2015 - Opportunities and challenges in multi-modal sensing for regular lifestyle tracking.pdf:pdf},
isbn = {978-1-4799-8425-1},
month = {mar},
pages = {225--227},
publisher = {IEEE},
series = {PerCom Workshops},
title = {{Opportunities and challenges in multi-modal sensing for regular lifestyle tracking}},
url = {http://ieeexplore.ieee.org/document/7134030/},
type={Workshop},
year = {2015}
}
@inproceedings{Sen2014,
abstract = {Using a 4 digit passcode as authentication is popular among most smartphone users. However, this type of authenti-cation is highly susceptible to a brute force or shoulder surfing attack. Further, it is not uncommon for close family members or friends to already be aware of this secret passcode. The key limitation of such an approach is that it is solely dependent on 'what a user knows'. We present an authentication mechanism that overcomes this limitation by including an additional factor of 'what a user is'. In our scheme, in addition to knowing the passcode, we capture the behaviour in which the passcode is entered. We model this behaviour in terms of the pressure applied on the screen by the user as well the duration the screen is pressed for. A key challenge of this approach is to ensure security without forgoing usability. This is particularly hard given the constraints of mobile computing. We tested our authentication mechanism through a user study of 10 participants and initial results show that our approach is both secure and usable.},
author = {Sen, Sougata and Muralidharan, Kartik},
booktitle = {International Conference on Mobile Computing and Ubiquitous Networking},
doi = {10.1109/ICMU.2014.6799058},
file = {:C$\backslash$:/Users/Sougata/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sen, Muralidharan - 2014 - Putting ‘pressure' on mobile authentication.pdf:pdf},
isbn = {978-1-4799-2231-4},
month = {jan},
pages = {56--61},
publisher = {IEEE},
series = {ICMU},
title = {{Putting ‘pressure' on mobile authentication}},
url = {http://ieeexplore.ieee.org/document/6799058/},
type={Conference},
year = {2014}
}
@inproceedings{Mo2014,
abstract = {In this paper, we reduce the energy overheads of continuous mobile sensing for context-aware applications that are interested in collective context or events. We propose a cloud-based query management and optimization framework, called CloQue, which can support concurrent queries, executing over thousands of individual smartphones. CloQue exploits correlation across context of different users to reduce energy overheads via two key innovations: i) Dynamically reordering the order of predicate processing to preferentially select predicates with not just lower sensing cost and higher selectivity, but that maximally reduce the uncertainty about other context predicates, and ii) intelligently propagating the query evaluation results to dynamically update the uncertainty of other correlated, but yet-to-be evaluated, context predicates. An evaluation, using real cell phone traces from a real world dataset shows significant energy savings (between 30 to 50{\%} compared with traditional short-circuit systems) with little loss in accuracy (5{\%} at most).},
author = {Mo, Tianli and Sen, Sougata and Lim, Lipyeow and Misra, Archan and Balan, Rajesh Krishna and Lee, Youngki},
booktitle = {International Conference on Mobile Data Management},
doi = {10.1109/MDM.2014.33},
isbn = {9781479957057},
issn = {15516245},
keywords = {Collaborative Sensing,Mobile Phone Sensing,Power Management,Query Optimization},
series = {MDM},
title = {{Cloud-based query evaluation for energy-efficient mobile sensing}},
type={Conference},
volume = {1},
year = {2014}
}
@inproceedings{Sen2014a,
abstract = {This paper explores the possibility of using mobile sensing data to detect certain in-store shopping intentions or behaviours of shoppers. We propose a person-independent activity recognition technique called CROSDAC1, which captures the diversity in the manifestation of such intentions or behaviours in a heterogeneous set of users in a data-driven manner via a 2-stage clustering-cum-classification technique. Using smartphone based sensor data (accelerometer, compass and Wi-Fi) from a directed, but real-life study involving 86 shopping episodes from 30 users in a mall's food court, we show that CROSDAC's mobile sensing-based approach can offer reasonably high accuracy (77:6{\%} for a 2-class identification problem) and outperforms the traditional communitydriven approaches that unquestioningly segment users on the basis of underlying demographic or lifestyle attributes.},
address = {New York, New York, USA},
author = {Sen, Sougata and Chakraborty, Dipanjan and Subbaraju, Vigneshwaran and Banerjee, Dipyaman and Misra, Archan and Banerjee, Nilanjan and Mittal, Sumit},
booktitle = {International Symposium on Wearable Computers},
doi = {10.1145/2634317.2634338},
file = {:C$\backslash$:/Users/Sougata/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sen et al. - 2014 - Accommodating user diversity for in-store shopping behavior recognition.pdf:pdf},
isbn = {9781450329699},
issn = {15504816},
keywords = {Activity recognition,Mobile-sensing,Shopping behavior},
pages = {11--14},
publisher = {ACM Press},
series = {ISWC},
title = {{Accommodating user diversity for in-store shopping behavior recognition}},
url = {http://dl.acm.org/citation.cfm?doid=2634317.2634338},
type={Conference},
year = {2014}
}
@inproceedings{Sen2012,
abstract = {We make the case for cloud-enabled mobile sensing services that support an emerging application class, one which infers near-real time collective context using sensor data obtained continuously from a large set of consumer mobile devices. We present the high-level architecture and functional requirements for such a mobile sensing service, and argue that such a service can significantly improve the scalability and energy-efficiency of large-scale mobile sensing by coordinating the sensing {\&} processing tasks across multiple devices. We then focus specifically on the problem of energy-efficiency and provide early exemplars of how optimizing query execution jointly over multiple phones can lead to substantial energy savings.},
address = {New York, New York, USA},
author = {Sen, Sougata and Misra, Archan and Balan, Rajesh and Lim, Lipyeow},
booktitle = {Proceedings of MCC workshop on Mobile cloud computing},
doi = {10.1145/2342509.2342521},
file = {:C$\backslash$:/Users/Sougata/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sen et al. - 2012 - The case for cloud-enabled mobile sensing services.pdf:pdf},
isbn = {9781450315197},
pages = {53},
publisher = {ACM Press},
series = {MCC},
title = {{The case for cloud-enabled mobile sensing services}},
url = {http://dl.acm.org/citation.cfm?doid=2342509.2342521},
type={Workshop},
year = {2012}
}
@inproceedings{Padmanabh2009,
abstract = {In this paper, we have studied the IT system (e.g. MS-outlook) that is used to book meeting rooms in a corporate environment. In the existing IT system, the status of meeting rooms is manually entered, and as a result, it is not reflected in real time in the IT system. This results in severe underutilization of resources (conference rooms) across the corporation, and wastage of electricity with the lights and air-conditioning system being operational even when the rooms are unoccupied. We have created a test bed of motes and analyzed the occupancy and electricity consumption data to estimate the under-utilization of conference rooms, and the wastage of electricity in the process. In order to eliminate these problems, we have designed a wireless sensor network based solution which results in two main benefits: (i) the utilization of the conference room is increased from 67{\%} to 90{\%} and (ii) electricity saving is equivalent to 16000 full grown banyan trees in a year. {\textcopyright} 2010 ACM.},
address = {New York, New York, USA},
author = {Padmanabh, Kumar and {Malikarjuna V}, Adi and Sen, Sougata and Katru, Siva Prasad and Kumar, Amrit and {Sai Pawankumar}, C. and Vuppala, Sunil Kumar and Paul, Sanjoy},
booktitle = {Workshop on Embedded Sensing Systems for Energy-Efficiency in Buildings},
doi = {10.1145/1810279.1810288},
isbn = {9781605588247},
keywords = {carbon emission,carbon footprints,occupancy detection,wireless sensor network},
pages = {37--42},
publisher = {ACM Press},
series = {BuildSys},
title = {{ISense: A wireless sensor network based conference room management system}},
url = {http://portal.acm.org/citation.cfm?doid=1810279.1810288},
type={Workshop},
year = {2009}
}
@inproceedings{Padmanabh2007,
abstract = {Wireless Sensor Network (WSN) is characterized with limited battery power and limited computation capability. Sensor nodes which produce a data set that is different from their counter parts are called Outlier nodes. For example, in a particular room, if we expect temperature of 25°C and if we receive a temperature reading of 73°C. This is called outlier data and the node which produces this data is called outliers nodes. We are considering a system where user is interested only in outlier data. We assumed that outlier data is generated due to the ambiance parameter. We also assumed that instead of sending all the sensed data, nodes are required to send the outlier data in response to a query from the base station. In this paper we found that using traditional routing protocol for communications is not an optimum solution. Traditional routing protocols consume more memory and battery power in the route-request process. We have also suggested that use of "Random Walk on Random Graph Technique" reduces the overhead of transmitting packets. We have proved this with analysis and simulation. We argue that with random walk on random graph mechanism, energy consumption is minimized and numbers of packets flooded in the network is very less.},
author = {Padmanabh, Kumar and Adi, Mallikarjuna Reddy V and Sen, Sougata and Gupta, Puneet},
booktitle = {International Conference on Wireless Communication and Sensor Networks},
doi = {10.1109/WCSN.2007.4475745},
isbn = {978-1-4244-1877-0},
month = {dec},
pages = {45--49},
publisher = {IEEE},
series = {WCSN},
title = {{Random Walk on Random Graph based Outlier Detection in Wireless Sensor Networks}},
url = {http://ieeexplore.ieee.org/document/4475745/},
type={Conference},
year = {2007}
}
