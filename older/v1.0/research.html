<!DOCTYPE html>
<html lang="en">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <title>Sougata Sen</title>

    <meta name="description" content="">
    <meta name="author" content="">

                <link  rel="stylesheet" href="css/style.css" />
                <script src="js/jquery-3.3.1.min.js"></script>
<script src=""></script>
        <script>
            $(function(){
                $("#header").load("commonHead.html");
            });
        </script>
</head>
<body>
        <div id="body-wrapper">

            <!-- Header -->
                <div id="header" class="container clearfix">
    </div>
    <div class="services-intro">
        <div class="fullTop2">&nbsp;</div>
          <div class="full1">
        <h3>Research Direction</h3>
            My research enables automatic and unobtrusive monitoring of fine-grained details of an individual's everyday activities and behaviors using sensor data from mobile, wearable, and infrastructure devices.  I focus on building systems that perform <i>lifestyle analytics</i>. In my work, I draw upon data from various sensing modalities; apply appropriate data processing and machine learning techniques to automatically and unobtrusively monitor an individual’s daily-life activities. The four high-level steps (or a subset of them) that I follow are:
        <BR><BR><BR>
            <img src="images/ResearchPipe.png" style="width:900px" />
            <!-- <I>Sense</I>: In my work, I draw upon data from various sensing modalities: personal devices such as smartphones, smartwatches, and more recently, smartrings; also IoT devices, such as Arduino boards with sensors, and BLE beacons.
        <BR>
            <I>Fuse</I>: I believe that every sensor present in these devices provides interesting and useful contextual insight about a certain lifestyle activity (e.g., a smartwatch might monitor the hand gesture during the eating activity, while the smartphone might determine whether the individual was sitting and eating), and fusing information from the right subset of sensors is useful in understanding specific aspects of an individual’s lifestyle.   
        <BR>
            <I>Infer</I>: I believe that although using the commonly used statistical features for activity inference can be useful, however, using hand-crafted features based on the monitored lifestyle can help in distinguishing it from other similar lifestyle activities. 

        <BR>
            <I>Improve</I>: This inference will open the doors for determining and providing potential suggestions for improving the individual’s lifestyle in particular and the overall community’s lifestyle in general.  -->

        <h3>Selected Active and Past projects</h3>
            <!-- Within the broader theme of lifestyle analytics, my recent research interests and accomplishments can be organized around: (i) daily life activity monitoring using personal sensing devices as well as infrastructure and IoT devices, and (ii) securely transferring sensitive information from these devices to a personal smartphone or tablet.
<BR>
        <h4>Daily Life Activity Monitoring</h4>
            While an individual can perform numerous everyday activities, my work thus far has focused on monitoring two activities -- <i>eating</i> and <i>shopping</i>.  -->
<BR>
<div class="horLine">
    &nbsp;
</div>


        <h4>Annapurna: Monitoring Eating using a smartwatch</h4>
            <table>
                <tr>
                    <td style = "colspan:250px;vertical-align: top;"><img src="./images/Annapurna.png" width="300px" /></td>
                    <td style = "vertical-align: top;padding-left: 20px">Annapurna uses the smartwatch's accelerometer and gyroscope sensor data to continuously to determine <i>when</i> an individual is eating. 
Once Annapurna detects the eating activity, it opportunistically triggers the smartwatch's embedded camera to capture images of the food being consumed. 
Annapurna passes these images through an image processing pipeline to identify <i>what</i> an individual is eating. 
Finally, Annapurna chooses a subset of the relevant images to create an automated food journal. Extensive details about Annapurna can be found in <a href="https://ieeexplore.ieee.org/abstract/document/7134103">paper-Sen15</a>, <a href="https://dl.acm.org/citation.cfm?id=3092306">paper-Sen17</a>, and <a href="https://ieeexplore.ieee.org/abstract/document/8449755">paper-Sen18</a><BR>
<a href="http://is.gd/annapurna">More info...</a></td>.

                </tr>
            </table>
<BR>
<div class="horLine">
    &nbsp;
</div>
        <h4>Auracle based Binge Eating Detection</h4>
<table>
                <tr>
                    <td style = "colspan:250px;vertical-align: top;"><img src="./images/binge.jpeg" width="250px" /></td>
                    <td style = "vertical-align: top;padding-left: 20px">Binge eating disorder (BED) is a severe, yet treatable eating disorder. Individuals suffering from BED often quickly consume unusually large amounts of food in a single eating session and feel the inability to stop eating. In this project we aim to automatically identify binge-eating episodes and collect user response to behavior-related questions during eating episodes. Recently, we have developed the Auracle device[<a href="https://auracle-project.org/">link</a>, <a href="https://dl.acm.org/citation.cfm?id=3264902">paper-Bi18</a>], a head-worn device that collects data from a microphone that is placed behind the ear, and uses this data to determine whether an individual is eating. In this project, we aim to extract fine-grained details related to the eating activity from the Auracle device. We hypothesize that such fine-grained information can help in distinguishing normal eating episodes from abnormal eating episodes such as binge-eating episodes; thus making the Auracle device useful for automatic binge-eating monitoring.
                        <BR>
                        <a href="https://auracle-project.org/">More info...</a>

                    </td>
                </tr>
            </table>
<BR>
<div class="horLine">
    &nbsp;
</div>




         </div>
         <div class="fullTop">&nbsp;</div>
     </div>
 </div>
</body>
</html>