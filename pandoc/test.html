<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>myPub</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<p><span class="citation" data-cites="phdthesis">@phdthesis</span>{sen2017fusing, title={Fusing mobile, wearable and infrastructure sensing for immersive daily lifestyle analytics}, author={Sen, Sougata}, year={2017}, school = {School of Information Systems, Singapore Management University}, note = {Advised by Prof. Archan Misra}, url = {https://ink.library.smu.edu.sg/etd_coll_all/23} }</p>
<p><span class="citation" data-cites="inproceedings">@inproceedings</span>{Sen15Case, author={Sen, Sougata and Subbaraju, Vigneshwaran and Misra, Archan and Balan, Rajesh and Lee, Youngki}, booktitle={IEEE International Conference on Pervasive Computing and Communication Workshops }, title={The case for smartwatch-based diet monitoring}, series ={PerCom Workshops ’15}, year={2015}, volume={}, number={}, pages={585-590}, keywords={accelerometers;gesture recognition;gyroscopes;image sensors;medical computing;patient monitoring;watches;wearable computers;smartwatch-based diet monitoring;gesture recognition;wrist-worn smartwatch;automated eating activity system;accelerometer;gyroscope data;eating episodes;noneating activities;smartwatch camera;offline analysis;automated image analyses;Sensors;Cameras;Accelerometers;Accuracy;Gyroscopes;Wrist;Feature extraction}, doi={10.1109/PERCOMW.2015.7134103}, location={St. Louis, MO}, ISSN={}, month={March}, abstract={We explore the use of gesture recognition on a wrist-worn smartwatch as an enabler of an automated eating activity (and diet monitoring) system. We show, using small-scale user studies, how it is possible to use the accelerometer and gyroscope data from a smartwatch to accurately separate eating episodes from similar non-eating activities, and to additionally identify the mode of eating (i.e., using a spoon, bare hands or chopsticks). Additionally, we investigate the likelihood of automatically triggering the smartwatch’s camera to capture clear images of the food being consumed, for possible offline analysis to identify what (and how much) the user is eating. Our results show both the promise and challenges of this vision: while opportune moments for capturing such useful images almost always exist in an eating episode, significant further work is needed to both (a) correctly identify the appropriate instant when the camera should be triggered and (b) reliably identify the type of food via automated analyses of such images.}, }</p>
<p><span class="citation" data-cites="inproceedings">@inproceedings</span>{Padmanabh09iSense, author = {Padmanabh, Kumar and Malikarjuna,V, Adi and Sen, Sougata and Katru, Siva Prasad and Kumar, Amrit and C, Sai Pawankumar and Vuppala, Sunil Kumar and Paul, Sanjoy}, title = {iSense: A Wireless Sensor Network Based Conference Room Management System}, booktitle = {ACM Workshop on Embedded Sensing Systems for Energy-Efficiency in Buildings}, series = {BuildSys ’09}, year = {2009}, isbn = {978-1-60558-824-7}, pages = {37–42}, url = {http://doi.acm.org/10.1145/1810279.1810288}, doi = {10.1145/1810279.1810288}, acmid = {1810288}, publisher = {ACM}, keywords = {carbon emission, carbon footprints, occupancy detection, wireless sensor network}, abstract={In this paper, we have studied the IT system (e.g. MS-outlook) that is used to book meeting rooms in a corporate environment. In the existing IT system, the status of meeting rooms is manually entered, and as a result, it is not reflected in real time in the IT system. This results in severe underutilization of resources (conference rooms) across the corporation, and wastage of electricity with the lights and air-conditioning system being operational even when the rooms are unoccupied. We have created a test bed of motes and analyzed the occupancy and electricity consumption data to estimate the under-utilization of conference rooms, and the wastage of electricity in the process. In order to eliminate these problems, we have designed a wireless sensor network based solution which results in two main benefits: (i) the utilization of the conference room is increased from 67% to 90% and (ii) electricity saving is equivalent to 16000 full grown banyan trees in a year.}, }</p>
<p><span class="citation" data-cites="INPROCEEDINGS">@INPROCEEDINGS</span>{Sen14Pressure, author={Sen, Sougata and Muralidharan, Kartik}, booktitle={IEEE International Conference on Mobile Computing and Ubiquitous Networking}, series={ICMU’14}, title={Putting ‘pressure’ on mobile authentication}, year={2014}, volume={}, number={}, pages={56-61}, location={Singapore}, keywords={authorisation;mobile computing;mobile authentication;authentication mechanism;mobile computing;brute force;shoulder surfing attack;secret passcode;Authentication;Mobile communication;Mobile handsets;Accuracy;Mobile computing;Vectors;Visualization}, doi={10.1109/ICMU.2014.6799058}, ISSN={}, month={Jan}, abstract={Using a 4 digit passcode as authentication is popular among most smartphone users. However, this type of authentication is highly susceptible to a brute force or shoulder surfing attack. Further, it is not uncommon for close family members or friends to already be aware of this secret passcode. The key limitation of such an approach is that it is solely dependent on <code>what a user knows'. We present an authentication mechanism that overcomes this limitation by including an additional factor of</code>what a user is’. In our scheme, in addition to knowing the passcode, we capture the behaviour in which the passcode is entered. We model this behaviour in terms of the pressure applied on the screen by the user as well the duration the screen is pressed for. A key challenge of this approach is to ensure security without forgoing usability. This is particularly hard given the constraints of mobile computing. We tested our authentication mechanism through a user study of 10 participants and initial results show that our approach is both secure and usable.}, }</p>
<p><span class="citation" data-cites="inproceedings">@inproceedings</span>{Sen12Cloud, author = {Sen, Sougata and Misra, Archan and Balan, Rajesh and Lim, Lipyeow}, title = {The Case for Cloud-enabled Mobile Sensing Services}, booktitle = {ACM Workshop on Mobile Cloud Computing}, series = {MCC ’12}, year = {2012}, isbn = {978-1-4503-1519-7}, pages = {53–58}, location={Helsinki, Finland}, url = {http://doi.acm.org/10.1145/2342509.2342521}, doi = {10.1145/2342509.2342521}, acmid = {2342521}, publisher = {ACM}, keywords = {mobile phone sensing, power management, query optimization}, abstract={We make the case for cloud-enabled mobile sensing services that support an emerging application class, one which infers near-real time collective context using sensor data obtained continuously from a large set of consumer mobile devices. We present the high-level architecture and functional requirements for such a mobile sensing service, and argue that such a service can significantly improve the scalability and energy-efficiency of large-scale mobile sensing by coordinating the sensing &amp; processing tasks across multiple devices. We then focus specifically on the problem of energy-efficiency and provide early exemplars of how optimizing query execution jointly over multiple phones can lead to substantial energy savings.}, }</p>
<p><span class="citation" data-cites="inproceedings">@inproceedings</span>{Sen14Accommodating, author = {Sen, Sougata and Chakraborty, Dipanjan and Subbaraju, Vigneshwaran and Banerjee, Dipyaman and Misra, Archan and Banerjee, Nilanjan and Mittal, Sumit}, title = {Accommodating User Diversity for In-store Shopping Behavior Recognition}, booktitle = {ACM International Symposium on Wearable Computers}, series = {ISWC ’14}, year = {2014}, isbn = {978-1-4503-2969-9}, location = {Seattle, Washington}, pages = {11–14}, numpages = {4}, url = {http://doi.acm.org/10.1145/2634317.2634338}, doi = {10.1145/2634317.2634338}, acmid = {2634338}, publisher = {ACM}, address = {New York, NY, USA}, keywords = {activity recognition, mobile-sensing, shopping behavior}, abstract={This paper explores the possibility of using mobile sensing data to detect certain in-store shopping intentions or behaviours of shoppers. We propose a person-independent activity recognition technique called CROSDAC, which captures the diversity in the manifestation of such intentions or behaviours in a heterogeneous set of users in a data-driven manner via a 2-stage clustering-cum-classification technique. Using smartphone based sensor data (accelerometer, compass and Wi-Fi) from a directed, but real-life study involving 86 shopping episodes from 30 users in a mall’s food court, we show that CROSDAC’s mobile sensing-based approach can offer reasonably high accuracy (77:6% for a 2-class identification problem) and outperforms the traditional community-driven approaches that unquestioningly segment users on the basis of underlying demographic or lifestyle attributes.}, }</p>
<p><span class="citation" data-cites="INPROCEEDINGS">@INPROCEEDINGS</span>{Radhakrishnan16IoT, author={Radhakrishnan, Meera and Sen, Sougata and Misra, Archan and Balan, Rajesh}, booktitle={IEEE International Conference on Communication Systems and Networks}, title={IoT+Small Data: Transforming in-store shopping analytics amp; services}, series={COMSNETS ’16}, location={Bangalore, India}, year={2016}, volume={}, number={}, pages={1-6}, keywords={cameras;data mining;Internet of Things;retail data processing;in-store shopping analytics;in-store shopping services;small data-based immersive retail analytics;sensor data combination;personal wearable-devices;store-deployed sensors;IoT devices;sensor mining;wearable data;shopper product-level interactions;power-hungry wearable sensors;shopper in-store activities;smartwatch-wearing users;grocery store interaction;item-picking gesture;smartwatch camera data;Accelerometers;Cameras;Object recognition;Image recognition;Performance evaluation;Real-time systems;Data mining}, doi={10.1109/COMSNETS.2016.7439946}, ISSN={2155-2509}, month={Jan}, abstract={We espouse a vision of small data-based immersive retail analytics, where a combination of sensor data, from personal wearable-devices and store-deployed sensors &amp; IoT devices, is used to create real-time, individualized services for in-store shoppers. Key challenges include (a) appropriate joint mining of sensor &amp; wearable data to capture a shopper’s product-level interactions, and (b) judicious triggering of power-hungry wearable sensors (e.g., camera) to capture only relevant portions of a shopper’s in-store activities. To explore the feasibility of our vision, we conducted experiments with 5 smartwatch-wearing users who interacted with objects placed on cupboard racks in our lab (to crudely mimic corresponding grocery store interactions). Initial results show significant promise: 94% accuracy in identifying an item-picking gesture, 85% accuracy in identifying the shelf-location from where the item was picked and 61% accuracy in identifying the exact item picked (via analysis of the smartwatch camera data).}, }</p>
<p><span class="citation" data-cites="INPROCEEDINGS">@INPROCEEDINGS</span>{Subbaraju15Using, author={Vigneshwaran, Subbaraju and Sen, Sougata and Misra, Archan and Chakraborti, Satyadip and Balan, Rajesh}, booktitle={IEEE International Conference on Pervasive Computing and Communications}, series={PerCom ‘15’}, title={Using infrastructure-provided context filters for efficient fine-grained activity sensing}, year={2015}, volume={}, number={}, pages={87-94}, location={St. Louis, MO}, keywords={gesture recognition;mobile computing;sensors;wearable computers;infrastructure-provided context filters;efficient fine-grained activity sensing;mobile sensing;wearable sensing;energy overheads;energy consumption reduction;infrastructure sensors;information sources;BLE beacons;fine-grained location context identification;switch pressing detection;water drinking identification;water cooler;room exit;lead time;triggered sensing;microscopic gesture recognition accuracy improvement;activity label reduction;empirical analysis;active sensing time reduction;fine-grained movement context identification;Mobile communication;Accuracy;Magnetic sensors;Context;Wearable sensors;Accelerometers}, doi={10.1109/PERCOM.2015.7146513}, ISSN={}, month={March}, abstract={While mobile and wearable sensing can capture unique insights into fine-grained activities (such as gestures and limb-based actions) at an individual level, their energy overheads are still prohibitive enough to prevent them from being executed continuously. In this paper, we explore practical alternatives to addressing this challenge-by exploring how cheap infrastructure sensors or information sources (e.g., BLE beacons) can be harnessed with such mobile/wearable sensors to provide an effective solution that reduces energy consumption without sacrificing accuracy. The key idea is that many fine-grained activities that we desire to capture are specific to certain location, movement or background context: infrastructure sensors and information sources (e.g., BLE beacons) offer practical and cheap ways to identify such context. In this paper, we first explore how various infrastructure, mobile &amp; wearable sensors can be used to identify fine-grained location/movement context (e.g., transiting through a door). We then show, using a couple of illustrative examples (specifically, the detection of <code>switch pressing' before exiting a room and the identification of</code>water drinking’ after approaching a water cooler) to show that such background context can be predicted, with sufficient accuracy, with sufficient lead time to enable a <code>triggered' model for mobile/wearable sensing of such microscopic, transient gestures and activities. Moreover, such</code>triggered’ sensing also helps to improve the accuracy of such microscopic gesture recognition, by reducing the set of candidate activity labels. Empirical experiments show that we are able to identify 82.2% of switch-pressing and 91.73% of water-drinking activities in a campus lab setting, with a significant reduction in active sensing time (up to 92.9% compared to continuous sensing).}, }</p>
<p><span class="citation" data-cites="article">@article</span>{MO17Cloud, title = {Cloud-based query evaluation for energy-efficient mobile sensing}, journal = {Pervasive and Mobile Computing}, volume = {38}, pages = {257 - 274}, year = {2017}, issn = {1574-1192}, doi = {https://doi.org/10.1016/j.pmcj.2016.12.005}, url = {http://www.sciencedirect.com/science/article/pii/S157411921630431X}, author = {Mo, Tianli and Lim, Lipyeow and Sen, Sougata and Misra, Archan and Balan, Rajesh and Lee, Youngki}, keywords = {Mobile sensing, Query evaluation, Energy-efficient}, abstract = {In this paper, we reduce the energy overheads of continuous mobile sensing, specifically for the case of context-aware applications that are interested in collective context or events, i.e.,¬†events expressed as a set of complex predicates over sensor data from multiple smartphones. We propose a cloud-based query management and optimization framework, called CloQue, that can support thousands of such concurrent queries, executing over a large number of individual smartphones. Our central insight is that the context of different individuals &amp; groups often have significant correlation, and that this correlation can be learned through standard association rule mining on historical data. CloQue‚Äôs¬†exploits such correlation to reduce energy overheads via two key innovations: (i) dynamically reordering the order of predicate processing to preferentially select predicates with not just lower sensing cost and higher selectivity, but that maximally reduce the uncertainty about other context predicates; and (ii) intelligently propagating the query evaluation results to dynamically update the confidence values of other correlated context predicates. We present techniques for probabilistic processing of context queries (to save significant energy at the cost of a query fidelity loss) and for query partitioning (to scale CloQue¬†to a large number of users while meeting latency bounds). An evaluation, using real cellphone traces from two different datasets, shows significant energy savings (between 30% and 50% compared with traditional short-circuit systems) with little loss in accuracy (5% at most). In addition, we utilize parallel evaluation to reduce overall latency. The experiments show our approaches save up to 70% latency.} }</p>
<p><span class="citation" data-cites="INPROCEEDINGS">@INPROCEEDINGS</span>{Padmanabh07Random, author={Padmanabh, Kumar and Reddy, Adi and Sen, Sougata and Gupta, Puneet}, booktitle={IEEE International Conference on Wireless Communication and Sensor Networks}, series={WCSN ‘07’}, title={Random Walk on Random Graph based Outlier Detection in Wireless Sensor Networks}, year={2007}, volume={}, number={}, pages={45-49}, keywords={data mining;wireless sensor networks;outlier detection;wireless sensor networks;random walk on random graph technique;Wireless sensor networks;Batteries;Temperature sensors;Routing protocols;Computer networks;Sensor phenomena and characterization;Counting circuits;Base stations;Analytical models;Energy consumption}, doi={10.1109/WCSN.2007.4475745}, ISSN={}, month={Dec}, abstract={Wireless Sensor Network (WSN) is characterized with limited battery power and limited computation capability. Sensor nodes which produce a data set that is different from their counter parts are called Outlier nodes. For example, in a particular room, if we expect temperature of 25degC and if we receive a temperature reading of 73degC. This is called outlier data and the node which produces this data is called outliers nodes. We are considering a system where user is interested only in outlier data. We assumed that outlier data is generated due to the ambiance parameter. We also assumed that instead of sending all the sensed data, nodes are required to send the outlier data in response to a query from the base station. In this paper we found that using traditional routing protocol for communications is not an optimum solution. Traditional routing protocols consume more memory and battery power in the route-request process. We have also suggested that use of “Random Walk on Random Graph Technique” reduces the overhead of transmitting packets. We have proved this with analysis and simulation. We argue that with random walk on random graph mechanism, energy consumption is minimized and numbers of packets flooded in the network is very less.}, }</p>
<p><span class="citation" data-cites="inproceedings">@inproceedings</span>{Sen17Experiences, author = {Sen, Sougata and Subbaraju, Vigneshwaran and Misra, Archan and Balan, Rajesh Krishna and Lee, Youngki}, title = {Experiences in Building a Real-World Eating Recogniser}, booktitle = {ACM International on Workshop on Physical Analytics}, series = {WPA ’17}, year = {2017}, isbn = {978-1-4503-4958-1}, location = {Niagara Falls, New York, USA}, pages = {7–12}, url = {http://doi.acm.org/10.1145/3092305.3092306}, doi = {10.1145/3092305.3092306}, acmid = {3092306}, publisher = {ACM}, address = {New York, NY, USA}, keywords = {activity recognition, eating detection, food journaling, smartwatch}, abstract={In this paper, we describe the progressive design of the gesture recognition module of an automated food journaling system – Annapurna. Annapurna runs on a smartwatch and utilises data from the inertial sensors to first identify eating gestures, and then captures food images which are presented to the user in the form of a food journal. We detail the lessons we learnt from multiple in-the-wild studies, and show how eating recognizer is refined to tackle challenges such as (i) high gestural diversity, and (ii) non-eating activities with similar gestural signatures. Annapurna is finally robust (identifying eating across a wide diversity in food content, eating styles and environments) and accurate (false-positive and false-negative rates of 6.5% and 3.3% respectively)}, }</p>
<p><span class="citation" data-cites="INPROCEEDINGS">@INPROCEEDINGS</span>{Sen16Foosball, author={Sen, Sougata and Rachuri, Kiran and Mukherji, Abhishek and Misra, Archan}, booktitle={IEEE International Conference on Pervasive Computing and Communication Workshops}, series={PerCom Workshops ’16}, title={Did you take a break today? Detecting playing foosball using your smartwatch}, year={2016}, volume={}, number={}, pages={1-6}, keywords={employee welfare;gesture recognition;graphical user interfaces;occupational health;occupational stress;sport;smart watch;working hours;work-related injuries;RSI;work-life imbalance;stress reduction;exhaustion reduction;productivity improvement;employee bonding improvement;camaraderie improvement;healthy-work-break balance;foosball break detection;United States;wrist movement;hand movement;wrist-worn device;Feature extraction;Games;Accelerometers;Employment;Sensors;Stress;Bars}, doi={10.1109/PERCOMW.2016.7457165}, ISSN={}, month={March}, abstract={Prolonged working hours are a primary cause of stress, work related injuries (e.g, RSIs), and work-life imbalance in employees at a workplace. As reported by some studies, taking timely breaks from continuous work not only reduces stress and exhaustion but also improves productivity, employee bonding, and camaraderie. Our goal is to build a system that automatically detects breaks thereby assisting in maintaining healthy work-break balance. In this paper, we focus on detecting foosball breaks of employees at a workplace using a smartwatch. We selected foosball as it is one of the most commonly played games at many workplaces in the United States. Since playing foosball involves wrist and hand movement, a wrist-worn device (e.g., a smartwatch), due to its position, has a clear advantage over a smartphone for detecting foosball activity. Our evaluation using data collected from real workplace shows that we can identify with more than 95% accuracy whether a person is playing foosball or not. We also show that we can determine how long a foosball session lasted with an error of less than 3% in the best case.}, }</p>
<p><span class="citation" data-cites="inproceedings">@inproceedings</span>{Mishra18Case, author = {Mishra, Varun and Pope, Gunnar and Lord, Sarah and Lewia, Stephanie and Lowens, Byron and Caine, Kelly and Sen, Sougata and Halter, Ryan and Kotz, David}, title = {The Case for a Commodity Hardware Solution for Stress Detection}, booktitle = {ACM International Joint Conference and International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers}, series = {UbiComp ’18 Adjunct}, year = {2018}, isbn = {978-1-4503-5966-5}, location = {Singapore, Singapore}, pages = {1717–1728}, numpages = {12}, url = {http://doi.acm.org/10.1145/3267305.3267538}, doi = {10.1145/3267305.3267538}, acmid = {3267538}, publisher = {ACM}, address = {New York, NY, USA}, keywords = {Stress detection, commodity wearables, mental health, mobile health (mHealth)}, abstract={Timely detection of an individual’s stress level has the potential to expedite and improve stress management, thereby reducing the risk of adverse health consequences that may arise due to unawareness or mismanagement of stress. Recent advances in wearable sensing have resulted in multiple approaches to detect and monitor stress with varying levels of accuracy. The most accurate methods, however, rely on clinical grade sensors strapped to the user. These sensors measure physiological signals of a person and are often bulky, custom-made, expensive, and/or in limited supply, hence limiting their large-scale adoption by researchers and the general public. In this paper, we explore the viability of commercially available off-the-shelf sensors for stress monitoring. The idea is to be able to use cheap, non-clinical sensors to capture physiological signals, and make inferences about the wearer’s stress level based on that data. In this paper, we describe a system involving a popular off-the-shelf heart-rate monitor, the Polar H7; we evaluated our system in a lab setting with three well-validated stress-inducing stimuli with 26 participants. Our analysis shows that using the off-the-shelf sensor alone, we were able to detect stressful events with an F1 score of 0.81, on par with clinical-grade sensors.}, }</p>
<p><span class="citation" data-cites="INPROCEEDINGS">@INPROCEEDINGS</span>{Sen17Inferring, author={Sen, Sougata and Grover, Karan and Subbaraju, Vigneshwaran and Misra, Archan}, booktitle={IEEE International Conference on Pervasive Computing and Communications Workshops}, series={PerCom Workshops ’17}, title={Inferring smartphone keypress via smartwatch inertial sensing}, year={2017}, volume={}, number={}, pages={685-690}, keywords={haptic interfaces;mobile computing;smart phones;watches;smartwatch inertial sensing;smartphone keypress;qwerty keyboard;smartphone;macro-gesture recognition;Feature extraction;Presses;Data collection;Wrist;Data mining;Accelerometers}, doi={10.1109/PERCOMW.2017.7917646}, ISSN={}, month={March}, abstract={Due to numerous benefits, sensor-rich smartwatches and wrist-worn wearable devices are quickly gaining popularity. The popularity of these devices also raises privacy concerns. In this paper we explore one such privacy concern: the possibility of extracting the location of a user’s touch-event on a smartphone, using the inertial sensor data of a smartwatch worn by the user on the same arm. This is a major concern not only because it might be possible for an attacker to extract private and sensitive information from the inputs provided but also because the attack mode utilises a device (smartwatch) that is distinct from the device being attacked (smartphone). Through a user study we find that such attacks are possible. Specifically, we can infer the user’s entry pattern on a qwerty keyboard, with an error bound of ±2 neighboring keys, with 73.85% accuracy. As a possible preventive mechanism, we also show that adding a little white noise to inertial sensor data can reduce the inference accuracy by almost 30%, without affecting the accuracy of macro-gesture recognition.}, }</p>
<p><span class="citation" data-cites="inproceedings">@inproceedings</span>{Radhakrishnan2016Demo, author = {Radhakrishnan, Meeralakshmi and Eswaran, Sharanya and Sen, Sougata and Subbaraju, Vigneswaran and Misra, Archan and Balan, Rajesh Krishna}, title = {Demo: Smartwatch Based Shopping Gesture Recognition}, booktitle = {Proceedings of the International Conference on Mobile Systems, Applications, and Services}, series = {MobiSys ’16}, year = {2016}, isbn = {978-1-4503-4416-6}, location = {Singapore, Singapore}, pages = {115–115}, numpages = {1}, url = {http://doi.acm.org/10.1145/2938559.2938572}, doi = {10.1145/2938559.2938572}, acmid = {2938572}, publisher = {ACM}, address = {New York, NY, USA}, keywords = {gesture recognition, shopping, wearable sensing}, }</p>
<p><span class="citation" data-cites="INPROCEEDINGS">@INPROCEEDINGS</span>{Radhakrishnan18Smart, author={Radhakrishnan, Meera and Sen, Sougata and Misra, Archan and Lee, Youngki and Balan, Rajesh}, booktitle={IEEE International Conference on Communication Systems Networks}, series={COMSNETS ’18}, title={Smart monitoring via participatory BLE relaying}, year={2018}, volume={}, number={}, pages={312-319}, doi={10.1109/COMSNETS.2018.8328213}, % ISSN={2155-2509}, month={Jan}, abstract={We espouse the vision of a smart object/campus architecture where sensors attached to smart objects use BLE as communication interface, and where smartphones act as opportunistic relays to transfer the data. We explore the feasibility of the vision with real-world Wi-Fi based location traces from our university campus. Our feasibility studies establish that redundancy exists in user movement within the indoor spaces, and that this redundancy can be exploited for collecting sensor data in an opportunistic, yet fair manner. We develop a couple of alternative heuristics that address the BLE energy asymmetry challenge by intelligently duty-cycling the scanning actions of individual devices. We evaluate the efficacy and tradeoffs of the proposed approaches by simulation experiments with real-world location traces.}, }</p>
<p><span class="citation" data-cites="inproceedings">@inproceedings</span>{Sen2016Demo, author = {Sen, Sougata and Subbaraju, Vigneshwaran and Misra, Archan and Lee, Youngki and Balan, Rajesh Krishna}, title = {Demo: Smartwatch Based Food Diary &amp; Eating Analytics}, booktitle = {Proceedings of the International Conference on Mobile Systems, Applications, and Services}, series = {MobiSys ’16}, year = {2016}, isbn = {978-1-4503-4416-6}, location = {Singapore, Singapore}, pages = {118–118}, numpages = {1}, url = {http://doi.acm.org/10.1145/2938559.2938569}, doi = {10.1145/2938559.2938569}, acmid = {2938569}, publisher = {ACM}, address = {New York, NY, USA}, keywords = {eating detection, smartwatch}, abstract={Monitoring an individual’s daily dietary intake can provide various insights regarding the health of the individual. Applications such as My Fitness Pal exists, which allows individuals to monitor all items that the individual consumed. However, manual monitoring can be labour intensive. To overcome this limitation, wrist worn sensor based eating habit monitoring has been studied by various researchers. These systems can detect eating gesture, but they cannot determine what is being eaten. We have built a system which can (i) detect eating gesture using the smartwatch’s inertial sensors (ii) use the smartwatch’s camera to capture images of food consumed at opportune moment and (iii) present the images to the user at the end of day. Key challenges in building the system are:(i) limited battery (ii) diversity in eating style and (iii) latency in camera triggering.}, }</p>
<p><span class="citation" data-cites="inproceedings">@inproceedings</span>{Sen2018i4s, author = {Sen, Sougata and Misra, Archan and Subbaraju, Vigneshwaran and Grover, Karan and Radhakrishnan, Meera and Balan, Rajesh K. and Lee, Youngki}, title = {I<span class="math inline"><em></em><sup>4</sup></span>{S}: Capturing Shopper’s In-store Interactions}, booktitle = {ACM International Symposium on Wearable Computers}, series = {ISWC ’18}, year = {2018}, pages = {156–159}, isbn = {978-1-4503-5967-2}, location = {Singapore, Singapore}, url = {http://doi.acm.org/10.1145/3267242.3267259}, doi = {10.1145/3267242.3267259}, acmid = {3267259}, abstract={In this paper, we present I 4 S, a system that identifies item interactions of customers in a retail store through sensor data fusion from smartwatches, smartphones and distributed BLE beacons. To identify these interactions, I 4 S builds a gesture-triggered pipeline that (a) detects the occurrence of" item picks", and (b) performs fine-grained localization of such pickup gestures. By analyzing data collected from 31 shoppers visiting a midsized stationary store, we show that we can identify person-independent picking gestures with a precision of over 88%, and identify the rack from where the pick occurred with 91%+ precision (for popular racks).}, } <span class="citation" data-cites="article">@article</span>{Bi2018auracle, author = {Bi, Shengjie and Wang, Tao and Tobias, Nicole and Nordrum, Josephine and Wang, Shang and Halvorsen, George and Sen, Sougata and Peterson, Ronald and Odame, Kofi and Caine, Kelly and Halter, Ryan and Sorber, Jacob and Kotz, David}, title = {Auracle: Detecting Eating Episodes with an Ear-mounted Sensor}, journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.}, issue_date = {September 2018}, volume = {2}, number = {3}, month = sep, year = {2018}, issn = {2474-9567}, pages = {92:1–92:27}, articleno = {92}, numpages = {27}, url = {http://doi.acm.org/10.1145/3264902}, doi = {10.1145/3264902}, acmid = {3264902}, publisher = {ACM}, address = {New York, NY, USA}, abstract={In this paper, we propose Auracle, a wearable earpiece that can automatically recognize eating behavior. More specifically, in free-living conditions, we can recognize when and for how long a person is eating. Using an off-the-shelf contact microphone placed behind the ear, Auracle captures the sound of a person chewing as it passes through the bone and tissue of the head. This audio data is then processed by a custom analog/digital circuit board. To ensure reliable (yet comfortable) contact between microphone and skin, all hardware components are incorporated into a 3D-printed behind-the-head framework. We collected field data with 14 participants for 32 hours in free-living conditions and additional eating data with 10 participants for 2 hours in a laboratory setting. We achieved accuracy exceeding 92.8% and F1 score exceeding 77.5% for eating detection. Moreover, Auracle successfully detected 20-24 eating episodes (depending on the metrics) out of 26 in free-living conditions. We demonstrate that our custom device could sense, process, and classify audio data in real time. Additionally, we estimate Auracle can last 28.1 hours with a 110 mAh battery while communicating its observations of eating behavior to a smartphone over Bluetooth.}, }</p>
<p><span class="citation" data-cites="inproceedings">@inproceedings</span>{Sen2018Annapurna, author={Sen, Sougata and Subbaraju, Vigneshwaran and Misra, Archan and Balan, Rajesh and Lee, Youngki}, booktitle={IEEE International Symposium on A World of Wireless, Mobile and Multimedia Networks}, series={WoWMoM ’18}, title={Annapurna: Building a Real-World Smartwatch-Based Automated Food Journal}, year={2018}, pages={1–6}, doi={10.1109/WoWMoM.2018.8449755}, ISSN={}, month={June}, abstract={We describe the design and implementation of a smartwatch-based, completely unobtrusive, food journaling system, where the smartwatch helps to intelligently capture useful images of food that an individual consumes throughout the day. The overall system, called Annapurna, is based on three key components: (a) a smartwatch-based gesture recognizer to identify eating gestures, (b) a smartwatch-based image capturer that obtains a small set of relevant and useful images with a low energy overhead, and (c) a server-based image filtering engine that removes irrelevant uploaded images, and then catalogs them through a portal. Our primary challenge is to make the system robust to the huge diversity in natural eating habits and food choices. We show how we address this by an appropriate coupling between a smartwatch’s camera sensor and inertial sensor-based tracking of eating gestures, thereby helping to capture multiple likely-to-be-useful images with low energy overhead. Through a series of real-world, in-the-wild studies, we demonstrate the end-to-end working of Annapurna, which captures useful images in over 95% of all natural eating episodes.}, }</p>
<p><span class="citation" data-cites="ARTICLE">@ARTICLE</span>{Mikusz16MobiSys, author={Mikusz, Mateusz and Clinch, Sarah and Sen, Sougata}, journal={IEEE Pervasive Computing}, title={MobiSys 2016}, year={2016}, volume={15}, number={4}, pages={85-88}, keywords={pervasive computing;mobile;Internet of Things;Internet/Web technologies;MobiSys;security;networking}, doi={10.1109/MPRV.2016.62}, ISSN={1536-1268}, month={Oct}, abstract={The 14th ACM International Conference on Mobile Systems, Applications, and Services (MobiSys 2016) spanned a range of themes and domains, from smart environments to security and privacy. The highlights presented here cover the keynotes, paper sessions, and first Asian Students Symposium on Emerging Technologies.}, }</p>
<p><span class="citation" data-cites="incollection">@incollection</span>{padmanabh2016zigbee, title={ZigBee versus Other Protocols and Standards}, author={Padmanabh, Kumar and Sen, Sougata and Paul, Sanjoy}, booktitle={ZigBee{} Network Protocols and Applications}, pages={319–362}, year={2016}, publisher={Auerbach Publications}, }</p>
<p><span class="citation" data-cites="INPROCEEDINGS">@INPROCEEDINGS</span>{Sen16Pervasive, author={Sen, Sougata}, booktitle={IEEE International Conference on Communication Systems and Networks}, series={COMSNETS ’16}, title={Pervasive physical analytics using multi-modal sensing}, year={2016}, volume={}, number={}, pages={1-2}, keywords={locomotives;monitoring;sensors;wearable computers;pervasive physical analytics;multimodal sensing;wearable devices;mobile devices;unobtrusive monitoring;ADL monitoring systems;automatic monitoring;Monitoring;Sensors;Context;Mobile communication;Energy consumption;Biomedical monitoring;Buildings}, doi={10.1109/COMSNETS.2016.7439998}, ISSN={2155-2509}, month={Jan}, abstract={With the gradual increase in the number of individually owned mobile and wearable devices, as well as increase in the number of publicly available sensing devices, automatic &amp; unobtrusive monitoring of Activities of Daily Living (ADLs) is gradually becoming possible. In this work, we discuss about the important trade-off between energy, accuracy and non-personalization that has to be considered while building commercially successful ADL monitoring systems. We then describe two ADL monitoring systems that we have built which addresses technical challenges pertaining to building ADL monitoring systems. We also outline our proposed next steps in this research.}, }</p>
<p><span class="citation" data-cites="INPROCEEDINGS">@INPROCEEDINGS</span>{Sen15Opportunities, author={Sen, Sougata}, booktitle={IEEE International Conference on Pervasive Computing and Communication Workshops}, series={PerCom Workshops ’15}, title={Opportunities and challenges in multi-modal sensing for regular lifestyle tracking}, year={2015}, volume={}, number={}, pages={225-227}, keywords={psychology;sensors;multimodal sensing;regular lifestyle tracking;publicly available sensors;personal sensors;activities-of-daily living;ADL profiling;ADL recording;sensor data processing;daily life tracker;ADL tracking systems;Sensors;Monitoring;Context;Mobile communication;Accuracy;Smart phones;Biomedical monitoring}, doi={10.1109/PERCOMW.2015.7134030}, ISSN={}, month={March}, abstract={With the availability of various publicly available and personal sensors, recording and profiling of activities of daily living (ADL) is becoming a reality. The sensors are omnipresent - in smartphones, smartwatches, and smartglasses and even in the environment around us in the form of peer smartphones or even infrastructure sensors such as bluetooth low energy beacons. However, there are various challenges pertaining to the sensor data processing, which makes creation of activities of daily life tracker challenging. In this work, we discuss about some of these challenges. We also discuss about some ADL tracking systems that we have developed and how we have addressed some of the challenges in building these systems. We further discuss about how various ADL trackers can be combined into a framework which can allow individuals to select a custom set of ADLs for self-tracking.}, }</p>
<p><span class="citation" data-cites="misc">@misc</span>{padmanabh13Dynamic, title={System and method for forming application dependent dynamic data packet in wireless sensor networks}, author={Padmanabh, Kumar and Gupta, Puneet and Sen, Sougata}, year={2013}, month={Nov}, note={US Patent number 8588192}, }</p>
<p><span class="citation" data-cites="misc">@misc</span>{padmanabh14Virtual, title={System and method for forming application dependent dynamic data packet in wireless sensor networks}, author={Padmanabh, Kumar and Reddy, Adi Mallikarjuna and Sen, Sougata and Kumar, Amrit and Gupta, Puneet and Malhotra, Lakshya and Vuppala, Sunil Kumar}, year={2014}, month={Feb}, note={US Patent number 8649298}, }</p>
<p><span class="citation" data-cites="misc">@misc</span>{sen14master, title={Method and system to dynamically detect and form a master slave network}, author={Sen, Sougata and Patil, Ketan and Ghosh, Animikh and Chauhan, Parag and Padmanabh, Kumar }, year={2014}, month={Oct}, note={US Patent number 8873429}, }</p>
<p><span class="citation" data-cites="inproceedings">@inproceedings</span>{sen2014shop, title={Poster: SHOP: Store Habits Of People}, author={Sen, Sougata and Chakraborty, Dipanjan and Banerjee, Dipyaman and Misra, Archan and Banerjee, Nilanjan and Subbaraju, Vigneshwaran and Mittal, Sumit} booktitle = {Workshop on Mobile Computing Systems and Applications (HotMobile ’14)} }</p>
</body>
</html>
