 <!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" /><meta http-equiv="Pragma" content="no-cache" /><meta http-equiv="Expires" content="0" />
<title>Sougata Sen</title><link rel="icon" href="images//favicon-32x32.png"><link  rel="stylesheet" href="css/style_2.0.0.css?v=2.0.2" /><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous"><link rel="stylesheet" href="css/academicons.min.css"/><link rel="stylesheet" type="text/css" href="css/basecss.css"><script src="js/jquery-3.3.1.min.js"></script><script src="js/func.js"></script><script>$(function(){$("#header").load("commonHead_2.0.0.html");});</script>
</head>
<body><div class="clearfix fit mxn2"><div class="col-10 px1 mx-auto"><div class=""><div class="overflow-hidden rounded"><div class="flex flex-column" style="min-height:100vh"><div id="header" class="container clearfix col-10" style="float: right;"></div><div id="main" class=" clearfix"><div class="col-11"><h3 style="float: right;">Jump to <a href="#thesis"> Thesis</a>&nbsp;|&nbsp;<a href="#papers">Journal, Conference and Workshop Publications</a>&nbsp;|&nbsp;<a href="#patents">Patents</a>&nbsp;|&nbsp;<a href="#book"> Book Chapters</a></h3></div><BR/><hr/><div class="col-11" id="thesis"><div class="clearfix justified"><h2 class="h2 upper">Thesis</h2><b>[T1]</b> <Me>Sougata Sen</Me>, "<paper>Fusing mobile, wearable and infrastructure sensing for immersive daily lifestyle analytics</paper>", Ph.D. thesis advised by Prof. Archan Misra, at School of Information Systems, Singapore Management University, 2017. <A id="bibTag" href="http://ink.library.smu.edu.sg/etd_coll_all/23/" style="color:#0074d9;font-weight:normal;">[link]</a></div></div><div class="col-11" id="papers"><div class="clearfix justified"><BR><h2 class="h2 upper">Journal, Conference and Workshop Publication</h2><h3 class="h3 upper">Journal Articles</h2><b>[J1]</b>&nbsp;<me>Sougata Sen</me>, Vigneshwaran Subbaraju, Archan Misra, Rajesh Balan, Youngki Lee, "<paper>Annapurna: An automated smartwatch-based eating detection and food journaling system</paper>",  Pervasive and Mobile Computing. 68(), 2020.<a data-toggle="collapse" href="javascript:toggleDiv('PJ1-abstract')">[Abstract]</a><div id='PJ1-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Maintaining a food journal can allow an individual to monitor eating habits, including unhealthy eating sessions, food items causing severe reactions, or portion size related information. However, manually maintaining a food journal can be burdensome. In this paper, we explore the vision of a pervasive, automated, completely unobtrusive, food journaling system using a commodity smartwatch. We present a prototype system — Annapurna— which is composed of three key components: (a) a smartwatch-based gesture recognizer that can robustly identify eating-specific gestures occurring anywhere, (b) a smartwatch-based image captor that obtains a small set of relevant images (containing views of the food being consumed) with a low energy overhead, and (c) a server-based image filtering engine that removes irrelevant uploaded images. Through lessons learnt from multiple user studies, we refine Annapurna progressively and show that our vision is indeed achievable: Annapurna can identify eating episodes and capture food images (involving a very wide diversity in food content, eating styles and environments) in over 95% of all free-living eating episodes.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1016/j.pmcj.2020.101259' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br></br><b>[J2]</b>&nbsp;Shibo Zhang, Yuqi Zhao, Dzung Tri Nguyen, Runsheng Xu, <me>Sougata Sen</me>, Josiah Hester, Nabil Alshurafa, "<paper>NeckSense: A Multi-Sensor Necklace for Detecting Eating Activities in Free-Living Conditions</paper>",  In Interactive, Mobile, Wearable and Ubiquitous Technologies. 37(4), 2020.<img src="images/prize.png" style="width: 25px;align:middle;white-space:nowrap;"><text style='color:red;align:middle;white-space:nowrap;'>[Best Presentation Runner-up at UbiComp/ISWC'20]</text></img>&nbsp;<a data-toggle="collapse" href="javascript:toggleDiv('PJ2-abstract')">[Abstract]</a><div id='PJ2-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">We present the design, implementation, and evaluation of a multi-sensor low-power necklace 'NeckSense' for automatically and unobtrusively capturing fine-grained information about an individual's eating activity and eating episodes, across an entire waking-day in a naturalistic setting. The NeckSense fuses and classifies the proximity of the necklace from the chin, the ambient light, the Lean Forward Angle, and the energy signals to determine chewing sequences, a building block of the eating activity. It then clusters the identified chewing sequences to determine eating episodes. We tested NeckSense with 11 obese and 9 non-obese participants across two studies, where we collected more than 470 hours of data in naturalistic setting. Our result demonstrates that NeckSense enables reliable eating-detection for an entire waking-day, even in free-living environments. Overall, our system achieves an F1-score of 81.6% in detecting eating episodes in an exploratory study. Moreover, our system can achieve a F1-score of 77.1% for episodes even in an all-day-around free-living setting. With more than 15.8 hours of battery-life NeckSense will allow researchers and dietitians to better understand natural chewing and eating behaviors, and also enable real-time interventions.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1145/3397313' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br></br><b>[J3]</b>&nbsp;Varun Mishra, Gunnar Pope, Sarah Lord, Stephanie Lewia, Byron Lowens, Kelly Caine, <me>Sougata Sen</me>, Ryan Halter, David Kotz, "<paper>Continuous Detection of Physiological Stress with Commodity Hardware</paper>",  ACM Transactions on Computing for Healthcare. 1(2), 2020.<a data-toggle="collapse" href="javascript:toggleDiv('PJ3-abstract')">[Abstract]</a><div id='PJ3-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Timely detection of an individual?s stress level has the potential to improve stress management, thereby reducing the risk of adverse health consequences that may arise due to mismanagement of stress. Recent advances in wearable sensing have resulted in multiple approaches to detect and monitor stress with varying levels of accuracy. The most accurate methods, however, rely on clinical-grade sensors to measure physiological signals; they are often bulky, custom-made, and expensive, hence limiting their adoption by researchers and the general public. In this paper, we explore the viability of commercially available off-the-shelf sensors for stress monitoring. The idea is to be able to use cheap, non-clinical sensors to capture physiological signals, and make inferences about the wearer?s stress level based on that data. We describe a system involving a popular off-the-shelf heart-rate monitor, the Polar H7; we evaluated our system with 26 participants in both a controlled lab setting with three well-validated stress-inducing stimuli and in free-living field conditions. Our analysis shows that using the off-the-shelf sensor alone, we were able to detect stressful events with an F1 score of 0.81 in the lab and 0.62 in the field, on par with clinical-grade sensors.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1145/3361562' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br></br><b>[J4]</b>&nbsp;Shengjie Bi, Kelly Caine, Ryan Halter, Jacob Sorber, David Kotz, Tao Wang, Nicole Tobias, Josephine Nordrum, Shang Wang, George Halvorsen, <me>Sougata Sen</me>, Ronald Peterson, Kofi Odame, "<paper>Auracle: Detecting Eating Episodes with an Ear-mounted Sensor</paper>",  In Interactive, Mobile, Wearable and Ubiquitous Technologies. 2(3), 2018.<a data-toggle="collapse" href="javascript:toggleDiv('PJ4-abstract')">[Abstract]</a><div id='PJ4-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we propose Auracle, a wearable earpiece that can automatically recognize eating behavior. More specifically, in free-living conditions, we can recognize when and for how long a person is eating. Using an off-the-shelf contact microphone placed behind the ear, Auracle captures the sound of a person chewing as it passes through the bone and tissue of the head. This audio data is then processed by a custom analog/digital circuit board. To ensure reliable (yet comfortable) contact between microphone and skin, all hardware components are incorporated into a 3D-printed behind-the-head framework. We collected field data with 14 participants for 32 hours in free-living conditions and additional eating data with 10 participants for 2 hours in a laboratory setting. We achieved accuracy exceeding 92.8% and F1 score exceeding 77.5% for eating detection. Moreover, Auracle successfully detected 20-24 eating episodes (depending on the metrics) out of 26 in free-living conditions. We demonstrate that our custom device could sense, process, and classify audio data in real time. Additionally, we estimate Auracle can last 28.1 hours with a 110 mAh battery while communicating its observations of eating behavior to a smartphone over Bluetooth.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1145/3264902' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br></br><b>[J5]</b>&nbsp;Tianli Mo, Lipyeow Lim, <me>Sougata Sen</me>, Archan Misra, Rajesh Krishna Balan, Youngki Lee, "<paper>Cloud-based query evaluation for energy-efficient mobile sensing</paper>",  Pervasive and Mobile Computing. 38(1), 2017.<a data-toggle="collapse" href="javascript:toggleDiv('PJ5-abstract')">[Abstract]</a><div id='PJ5-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we reduce the energy overheads of continuous mobile sensing, specifically for the case of context-aware applications that are interested in collective context or events, i.e., events expressed as a set of complex predicates over sensor data from multiple smartphones. We propose a cloud-based query management and optimization framework, called CloQue, that can support thousands of such concurrent queries, executing over a large number of individual smartphones. Our central insight is that the context of different individuals {\&} groups often have significant correlation, and that this correlation can be learned through standard association rule mining on historical data. CloQue's exploits such correlation to reduce energy overheads via two key innovations: (i) dynamically reordering the order of predicate processing to preferentially select predicates with not just lower sensing cost and higher selectivity, but that maximally reduce the uncertainty about other context predicates; and (ii) intelligently propagating the query evaluation results to dynamically update the confidence values of other correlated context predicates. We present techniques for probabilistic processing of context queries (to save significant energy at the cost of a query fidelity loss) and for query partitioning (to scale CloQue to a large number of users while meeting latency bounds). An evaluation, using real cellphone traces from two different datasets, shows significant energy savings (between 30% and 50% compared with traditional short-circuit systems) with little loss in accuracy (5% at most). In addition, we utilize parallel evaluation to reduce overall latency. The experiments show our approaches save up to 70% latency.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1016/j.pmcj.2016.12.005' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br></br><b>[J6]</b>&nbsp;Mateusz Mikusz, Sarah Clinch, <me>Sougata Sen</me>, "<paper>MobiSys 2016</paper>",  Pervasive Computing. 15(4), 2016.<a data-toggle="collapse" href="javascript:toggleDiv('PJ6-abstract')">[Abstract]</a><div id='PJ6-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">The 14th ACM International Conference on Mobile Systems, Applications, and Services (MobiSys 2016) spanned a range of themes and domains, from smart environments to security and privacy. The highlights presented here cover the keynotes, paper sessions, and first Asian Students Symposium on Emerging Technologies.</div>&nbsp;<a id="bibTag" href='http://ieeexplore.ieee.org/document/7676201/' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br></br><h3 class="h3 upper">Conference Papers</h2><b>[C1]</b>&nbsp;<me>Sougata Sen</me>, David Kotz, "<paper>VibeRing: Using vibrations from a smart ring as an out-of-band channel for sharing secret keys</paper>",  In Proceedings of the International Conference on the Internet of Things (IoT 2020).<img src="images/prize.png" style="width: 25px;align:middle;white-space:nowrap;"><text style='color:red;align:middle;white-space:nowrap;'>[Nominated as Candidate for Best Paper Award]</text></img>&nbsp;<a data-toggle="collapse" href="javascript:toggleDiv('PC1-abstract')">[Abstract]</a><div id='PC1-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">With the rapid growth in the number of IoT devices that have wireless communication capabilities, and sensitive information collection capabilities, it is becoming increasingly necessary to ensure that these devices communicate securely with only authorized devices. A major requirement of this secure communication is to ensure that both the devices share a \emph{secret}, which can be used for secure pairing and encrypted communication. Manually imparting this secret to these devices becomes an unnecessary overhead, especially when the device interaction is transient. In this paper, we empirically investigate the possibility of using an out-of-band communication channel -- vibration, generated by a custom smart ring, to share a secret with a smart IoT device. This exchanged secret can be used to bootstrap a secure wireless channel over which the devices can communicate. We believe that in future IoT devices can use such a technique to seamlessly connect with authorized devices with minimal user interaction overhead. In this paper, we specifically investigate (a) the feasibility of using vibration generated by a custom wearable for communication, (b) the effect of various parameters on this communication channel, and (c) the possibility of information manipulation by an adversary or information leakage to an adversary. For this investigation, we conducted a controlled study as well as a user study with 12 participants. In the controlled study, we could successfully share messages through vibrations with a bit error rate of less than 2.5\%. Additionally, through the user study we demonstrate that it is possible to share messages with various types of objects accurately, quickly and securely as compared to several existing techniques. Overall, we find that in the best case we can exchange 85.9\% messages successfully with a smart device.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1145/3410992.3410995' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[C2]</b>&nbsp;Shengjie Bi, Yiyang Lu, Nicole Tobias, Ella Ryan, Travis Masterson, <me>Sougata Sen</me>, Ryan Halter, Jacob Sorber, Diane Gilbert-Diamond, David Kotz, "<paper>Measuring children's eating behavior with a wearable device</paper>",  In International Conference on Healthcare Informatics (ICHI 2020).<a data-toggle="collapse" href="javascript:toggleDiv('PC2-abstract')">[Abstract]</a><div id='PC2-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Poor eating habits in children and teenagers can lead to obesity, eating disorders, or life-threatening health problems. Although researchers have studied children's eating behavior for decades, the research community has had limited technology to support the observation and measurement of fine-grained details of a child's eating behavior. In this paper, we present the feasibility of adapting the Auracle, an existing research-grade earpiece designed to automatically and unobtrusively recognize eating behavior in adults, for measuring children's eating behavior. We identified and addressed several challenges pertaining to monitoring eating behavior in children, paying particular attention to device fit and comfort. We also improved the accuracy and robustness of the eating-activity detection algorithms. We used this improved prototype in a lab study with a sample of 10 children for 60 total sessions and collected 22.3 hours of data in both meal and snack scenarios. Overall, we achieved an accuracy exceeding 85.0% and an F1 score exceeding 84.2% for eating detection with a 3-second resolution, and a 95.5% accuracy and a 95.7% F1 score for eating detection with a 1-minute resolution.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[C3]</b>&nbsp;<me>Sougata Sen</me>, Archan Misra, Vigneshwaran Subbaraju, Karan Grover, Meera Radhakrishnan, Rajesh K. Balan, Youngki Lee, "<paper>I4S: Capturing shopper's in-store interactions</paper>",  In International Symposium on Wearable Computers (ISWC 2018).<a data-toggle="collapse" href="javascript:toggleDiv('PC3-abstract')">[Abstract]</a><div id='PC3-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we present I 4 S, a system that identifies item interactions of customers in a retail store through sensor data fusion from smartwatches, smartphones and distributed BLE beacons. To identify these interactions, I 4 S builds a gesture-triggered pipeline that (a) detects the occurrence of ''item picks'', and (b) performs fine-grained localization of such pickup gestures. By analyzing data collected from 31 shoppers visiting a midsized stationary store, we show that we can identify person-independent picking gestures with a precision of over 88%, and identify the rack from where the pick occurred with 91%+ precision (for popular racks).</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1145/3267242.3267259' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[C4]</b>&nbsp;Meera Radhakrishnan, <me>Sougata Sen</me>, Archan Misra, Youngki Lee, Rajesh Krishna Balan, "<paper>Smart monitoring via participatory BLE relaying</paper>",  In International Conference on Communication Systems and Networks (COMSNETS 2018).<a data-toggle="collapse" href="javascript:toggleDiv('PC4-abstract')">[Abstract]</a><div id='PC4-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">We espouse the vision of a smart object/campus architecture where sensors attached to smart objects use BLE as communication interface, and where smartphones act as opportunistic relays to transfer the data. We explore the feasibility of the vision with real-world Wi-Fi based location traces from our university campus. Our feasibility studies establish that redundancy exists in user movement within the indoor spaces, and that this redundancy can be exploited for collecting sensor data in an opportunistic, yet fair manner. We develop a couple of alternative heuristics that address the BLE energy asymmetry challenge by intelligently duty-cycling the scanning actions of individual devices. We evaluate the efficacy and tradeoffs of the proposed approaches by simulation experiments with real-world location traces.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1109/COMSNETS.2018.8328213' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[C5]</b>&nbsp;<me>Sougata Sen</me>, Vigneshwaran Subbaraju, Archan Misra, Rajesh Balan, Youngki Lee, "<paper>Annapurna: Building a Real-World Smartwatch-Based Automated Food Journal</paper>",  In International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM 2018).<a data-toggle="collapse" href="javascript:toggleDiv('PC5-abstract')">[Abstract]</a><div id='PC5-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">We describe the design and implementation of a smartwatch-based, completely unobtrusive, food journaling system, where the smartwatch helps to intelligently capture useful images of food that an individual consumes throughout the day. The overall system, called Annapurna, is based on three key components: (a) a smartwatch-based gesture recognizer to identify eating gestures, (b) a smartwatch-based image capturer that obtains a small set of relevant and useful images with a low energy overhead, and (c) a server-based image filtering engine that removes irrelevant uploaded images, and then catalogs them through a portal. Our primary challenge is to make the system robust to the huge diversity in natural eating habits and food choices. We show how we address this by an appropriate coupling between a smartwatch's camera sensor and inertial sensor-based tracking of eating gestures, thereby helping to capture multiple likely-to-be-useful images with low energy overhead. Through a series of real-world, in-the-wild studies, we demonstrate the end-to-end working of Annapurna, which captures useful images in over 95% of all natural eating episodes.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1109/WoWMoM.2018.8449755' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[C6]</b>&nbsp;Meera Radhakrishnan, <me>Sougata Sen</me>, Vigneshwaran Subbaraju, Archan Misra, Rajesh Krishna Balan, "<paper>IoT+Small Data: Transforming in-store shopping analytics {\&} services</paper>",  In International Conference on Communication Systems and Networks (COMSNETS 2016).<a data-toggle="collapse" href="javascript:toggleDiv('PC6-abstract')">[Abstract]</a><div id='PC6-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">We espouse a vision of small data-based immersive retail analytics, where a combination of sensor data, from personal wearable-devices and store-deployed sensors {\&} IoT devices, is used to create real-Time, individualized services for in-store shoppers. Key challenges include (a) appropriate joint mining of sensor {\&} wearable data to capture a shopper's product-level interactions, and (b) judicious triggering of power-hungry wearable sensors (e.g., camera) to capture only relevant portions of a shopper's in-store activities. To explore the feasibility of our vision, we conducted experiments with 5 smartwatch-wearing users who interacted with objects placed on cupboard racks in our lab (to crudely mimic corresponding grocery store interactions). Initial results show significant promise: 94% accuracy in identifying an item-picking gesture, 85% accuracy in identifying the shelf-location from where the item was picked and 61% accuracy in identifying the exact item picked (via analysis of the smartwatch camera data).</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1109/COMSNETS.2016.7439946' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[C7]</b>&nbsp;S. Vigneshwaran, <me>Sougata Sen</me>, Archan Misra, Satyadip Chakraborti, Rajesh Krishna Balan, "<paper>Using infrastructure-provided context filters for efficient fine-grained activity sensing</paper>",  In International Conference on Pervasive Computing and Communications (PerCom 2015).<a data-toggle="collapse" href="javascript:toggleDiv('PC7-abstract')">[Abstract]</a><div id='PC7-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">While mobile and wearable sensing can capture unique insights into fine-grained activities (such as gestures and limb-based actions) at an individual level, their energy overheads are still prohibitive enough to prevent them from being executed continuously. In this paper, we explore practical alternatives to addressing this challenge-by exploring how cheap infrastructure sensors or information sources (e.g., BLE beacons) can be harnessed with such mobile/wearable sensors to provide an effective solution that reduces energy consumption without sacrificing accuracy. The key idea is that many fine-grained activities that we desire to capture are specific to certain location, movement or background context: infrastructure sensors and information sources (e.g., BLE beacons) offer practical and cheap ways to identify such context. In this paper, we first explore how various infrastructure, mobile {\&} wearable sensors can be used to identify fine-grained location/movement context (e.g., transiting through a door). We then show, using a couple of illustrative examples (specifically, the detection of `switch pressing' before exiting a room and the identification of `water drinking' after approaching a water cooler) to show that such background context can be predicted, with sufficient accuracy, with sufficient lead time to enable a `triggered' model for mobile/wearable sensing of such microscopic, transient gestures and activities. Moreover, such `triggered' sensing also helps to improve the accuracy of such microscopic gesture recognition, by reducing the set of candidate activity labels. Empirical experiments show that we are able to identify 82.2% of switch-pressing and 91.73% of water-drinking activities in a campus lab setting, with a significant reduction in active sensing time (up to 92.9% compared to continuous sensing).</div>&nbsp;<a id="bibTag" href='http://ieeexplore.ieee.org/document/7146513/' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[C8]</b>&nbsp;<me>Sougata Sen</me>, Kartik Muralidharan, "<paper>Putting ‘pressure' on mobile authentication</paper>",  In International Conference on Mobile Computing and Ubiquitous Networking (ICMU 2014).<a data-toggle="collapse" href="javascript:toggleDiv('PC8-abstract')">[Abstract]</a><div id='PC8-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Using a 4 digit passcode as authentication is popular among most smartphone users. However, this type of authenti-cation is highly susceptible to a brute force or shoulder surfing attack. Further, it is not uncommon for close family members or friends to already be aware of this secret passcode. The key limitation of such an approach is that it is solely dependent on 'what a user knows'. We present an authentication mechanism that overcomes this limitation by including an additional factor of 'what a user is'. In our scheme, in addition to knowing the passcode, we capture the behaviour in which the passcode is entered. We model this behaviour in terms of the pressure applied on the screen by the user as well the duration the screen is pressed for. A key challenge of this approach is to ensure security without forgoing usability. This is particularly hard given the constraints of mobile computing. We tested our authentication mechanism through a user study of 10 participants and initial results show that our approach is both secure and usable.</div>&nbsp;<a id="bibTag" href='http://ieeexplore.ieee.org/document/6799058/' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[C9]</b>&nbsp;Tianli Mo, <me>Sougata Sen</me>, Lipyeow Lim, Archan Misra, Rajesh Krishna Balan, Youngki Lee, "<paper>Cloud-based query evaluation for energy-efficient mobile sensing</paper>",  In International Conference on Mobile Data Management (MDM 2014).<a data-toggle="collapse" href="javascript:toggleDiv('PC9-abstract')">[Abstract]</a><div id='PC9-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we reduce the energy overheads of continuous mobile sensing for context-aware applications that are interested in collective context or events. We propose a cloud-based query management and optimization framework, called CloQue, which can support concurrent queries, executing over thousands of individual smartphones. CloQue exploits correlation across context of different users to reduce energy overheads via two key innovations: i) Dynamically reordering the order of predicate processing to preferentially select predicates with not just lower sensing cost and higher selectivity, but that maximally reduce the uncertainty about other context predicates, and ii) intelligently propagating the query evaluation results to dynamically update the uncertainty of other correlated, but yet-to-be evaluated, context predicates. An evaluation, using real cell phone traces from a real world dataset shows significant energy savings (between 30 to 50% compared with traditional short-circuit systems) with little loss in accuracy (5% at most).</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1109/MDM.2014.33' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[C10]</b>&nbsp;<me>Sougata Sen</me>, Dipanjan Chakraborty, Vigneshwaran Subbaraju, Dipyaman Banerjee, Archan Misra, Nilanjan Banerjee, Sumit Mittal, "<paper>Accommodating user diversity for in-store shopping behavior recognition</paper>",  In International Symposium on Wearable Computers (ISWC 2014).<a data-toggle="collapse" href="javascript:toggleDiv('PC10-abstract')">[Abstract]</a><div id='PC10-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">This paper explores the possibility of using mobile sensing data to detect certain in-store shopping intentions or behaviours of shoppers. We propose a person-independent activity recognition technique called CROSDAC1, which captures the diversity in the manifestation of such intentions or behaviours in a heterogeneous set of users in a data-driven manner via a 2-stage clustering-cum-classification technique. Using smartphone based sensor data (accelerometer, compass and Wi-Fi) from a directed, but real-life study involving 86 shopping episodes from 30 users in a mall's food court, we show that CROSDAC's mobile sensing-based approach can offer reasonably high accuracy (77:6% for a 2-class identification problem) and outperforms the traditional communitydriven approaches that unquestioningly segment users on the basis of underlying demographic or lifestyle attributes.</div>&nbsp;<a id="bibTag" href='http://dl.acm.org/citation.cfm?doid=2634317.2634338' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[C11]</b>&nbsp;Kumar Padmanabh, Mallikarjuna Reddy V Adi, <me>Sougata Sen</me>, Puneet Gupta, "<paper>Random Walk on Random Graph based Outlier Detection in Wireless Sensor Networks</paper>",  In International Conference on Wireless Communication and Sensor Networks (WCSN 2007).<a data-toggle="collapse" href="javascript:toggleDiv('PC11-abstract')">[Abstract]</a><div id='PC11-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Wireless Sensor Network (WSN) is characterized with limited battery power and limited computation capability. Sensor nodes which produce a data set that is different from their counter parts are called Outlier nodes. For example, in a particular room, if we expect temperature of 25°C and if we receive a temperature reading of 73°C. This is called outlier data and the node which produces this data is called outliers nodes. We are considering a system where user is interested only in outlier data. We assumed that outlier data is generated due to the ambiance parameter. We also assumed that instead of sending all the sensed data, nodes are required to send the outlier data in response to a query from the base station. In this paper we found that using traditional routing protocol for communications is not an optimum solution. Traditional routing protocols consume more memory and battery power in the route-request process. We have also suggested that use of "Random Walk on Random Graph Technique" reduces the overhead of transmitting packets. We have proved this with analysis and simulation. We argue that with random walk on random graph mechanism, energy consumption is minimized and numbers of packets flooded in the network is very less.</div>&nbsp;<a id="bibTag" href='http://ieeexplore.ieee.org/document/4475745/' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><h3 class="h3 upper">Workshop Papers and Consortia</h2><b>[W1]</b>&nbsp;Shibo Zhang, Qiuyang Xu, <me>Sougata Sen</me>, Nabil Alshurafa, "<paper>VibroScale: Turning Your Smartphone into a Weighing Scale</paper>",  In International Joint Conference on Pervasive and Ubiquitous Computing and International Symposium on Wearable Computers (UbiComp/ISWC Adjunct 2020).<img src="images/prize.png" style="width: 25px;align:middle;white-space:nowrap;"><text style='color:red;align:middle;white-space:nowrap;'>[Best Poster Award]</text></img>&nbsp;<a data-toggle="collapse" href="javascript:toggleDiv('PW1-abstract')">[Abstract]</a><div id='PW1-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Smartphones, with their ubiquity and plethora of embedded sensors enable on-the-go measurement. In this poster, we describe one novel measurement potential -- weight measurement -- by turning an everyday smartphone into a weighing scale. We describe VibroScale, our vibration-based approach to measuring weights of objects, that are small in size. Being able to objectively measure the weight of objects in free-living settings, without the burden of carrying a weighing scale has several possible use cases, particularly in weighing of small food items. We designed a smartphone app and regression algorithm that estimates the relative induced intensity of an object placed on the smartphone. We tested our proposed method on more than 50 fruits and other everyday objects of different sizes and weights. The results demonstrate that our smartphone-based method can measure the weight of fruits without relying on an actual weighing scale. Overall, we observed that VibroScale can measure one type of object with a mean absolute error of 12.4 grams. We believe that in future this approach can be generalized to estimate calories and measure weight of various types of objects.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1145/3410530.3414397' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[W2]</b>&nbsp;<me>Sougata Sen</me>, Varun Mishra, David Kotz, "<paper>Using Vibrations from a SmartRing as an Out-of-band Channel for Sharing Secret Keys</paper>",  In International Joint Conference on Pervasive and Ubiquitous Computing and International Symposium on Wearable Computers (UbiComp/ISWC Adjunct 2019).<a data-toggle="collapse" href="javascript:toggleDiv('PW2-abstract')">[Abstract]</a><div id='PW2-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">With the rapid growth in the number of Internet of Things (IoT) devices with wireless communication capabilities, and sensitive information collection capabilities, it is becoming increasingly necessary to ensure that these devices communicate securely with only authorized devices. A major requirement of this secure communication is to ensure that both the devices share a secret, which can be used for secure pairing and encrypted communication. Manually imparting this secret to these devices becomes an unnecessary overhead, especially when the device interaction is transient. In this work, we empirically investigate the possibility of using an out-of-band communication channel – vibration, generated by a custom smartRing – to share a secret with a compatible IoT device. Through a user study with 12 participants we show that in the best case we can exchange 85.9% messages successfully. Our technique demonstrates the possibility of sharing messages accurately, quickly and securely as compared to several existing techniques.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1145/3341162.3343818' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[W3]</b>&nbsp;Varun Mishra, Gunnar Pope, Sarah Lord, Stephanie Lewia, Byron Lowens, Kelly Caine, <me>Sougata Sen</me>, Ryan Halter, David Kotz, "<paper>The case for a commodity hardware solution for stress detection</paper>",  In International Joint Conference on Pervasive and Ubiquitous Computing and International Symposium on Wearable Computers (UbiComp/ISWC Adjunct 2018).<a data-toggle="collapse" href="javascript:toggleDiv('PW3-abstract')">[Abstract]</a><div id='PW3-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Timely detection of an individual's stress level has the potential to expedite and improve stress management, thereby reducing the risk of adverse health consequences that may arise due to unawareness or mismanagement of stress. Recent advances in wearable sensing have resulted in multiple approaches to detect and monitor stress with varying levels of accuracy. The most accurate methods, however, rely on clinical grade sensors strapped to the user. These sensors measure physiological signals of a person and are often bulky, custom-made, expensive, and/or in limited supply, hence limiting their large-scale adoption by researchers and the general public. In this paper, we explore the viability of commercially available off-the-shelf sensors for stress monitoring. The idea is to be able to use cheap, non-clinical sensors to capture physiological signals, and make inferences about the wearer's stress level based on that data. In this paper, we describe a system involving a popular off-the-shelf heart-rate monitor, the Polar H7; we evaluated our system in a lab setting with three well-validated stress-inducing stimuli with 26 participants. Our analysis shows that using the off-the-shelf sensor alone, we were able to detect stressful events with an F1 score of 0.81, on par with clinical-grade sensors.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1145/3267305.3267538' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[W4]</b>&nbsp;<me>Sougata Sen</me>, Karan Grover, Vigneshwaran Subbaraju, Archan Misra, "<paper>Inferring smartphone keypress via smartwatch inertial sensing</paper>",  In International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops 2017).<a data-toggle="collapse" href="javascript:toggleDiv('PW4-abstract')">[Abstract]</a><div id='PW4-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Due to numerous benefits, sensor-rich smartwatches and wrist-worn wearable devices are quickly gaining popularity. The popularity of these devices also raises privacy concerns. In this paper we explore one such privacy concern: the possibility of extracting the location of a user's touch-event on a smartphone, using the inertial sensor data of a smartwatch worn by the user on the same arm. This is a major concern not only because it might be possible for an attacker to extract private and sensitive information from the inputs provided but also because the attack mode utilises a device (smartwatch) that is distinct from the device being attacked (smartphone). Through a user study we find that such attacks are possible. Specifically, we can infer the user's entry pattern on a qwerty keyboard, with an error bound of ±2 neighboring keys, with 73.85% accuracy. As a possible preventive mechanism, we also show that adding a little white noise to inertial sensor data can reduce the inference accuracy by almost 30%, without affecting the accuracy of macro-gesture recognition.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1109/PERCOMW.2017.7917646' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[W5]</b>&nbsp;<me>Sougata Sen</me>, Vigneshwaran Subbaraju, Archan Misra, Rajesh Krishna Balan, Youngki Lee, "<paper>Experiences in Building a Real-World Eating Recogniser</paper>",  In International on Workshop on Physical Analytics (WPA 2017).<a data-toggle="collapse" href="javascript:toggleDiv('PW5-abstract')">[Abstract]</a><div id='PW5-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we describe the progressive design of the gesture recognition module of an automated food journaling system - Annapurna. Annapurna runs on a smartwatch and utilises data from the inertial sensors to first identify eating gestures, and then captures food images which are presented to the user in the form of a food journal. We detail the lessons we learnt from multiple in-the-wild studies, and show how eating recognizer is refined to tackle challenges such as (i) high gestural diversity, and (ii) non-eating activities with similar gestural signatures. Annapurna is finally robust (identifying eating across a wide diversity in food content, eating styles and environments) and accurate (false-positive and false-negative rates of 6.5% and 3.3% respectively).</div>&nbsp;<a id="bibTag" href='http://dl.acm.org/citation.cfm?doid=3092305.3092306' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[W6]</b>&nbsp;<me>Sougata Sen</me>, "<paper>Pervasive physical analytics using multi-modal sensing</paper>",  In International Conference on Communication Systems and Networks (COMSNETS 2016).<a data-toggle="collapse" href="javascript:toggleDiv('PW6-abstract')">[Abstract]</a><div id='PW6-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">With the gradual increase in the number of individually owned mobile and wearable devices, as well as increase in the number of publicly available sensing devices, automatic {\&} unobtrusive monitoring of Activities of Daily Living (ADLs) is gradually becoming possible. In this work, we discuss about the important trade-off between energy, accuracy and non-personalization that has to be considered while building commercially successful ADL monitoring systems. We then describe two ADL monitoring systems that we have built which addresses technical challenges pertaining to building ADL monitoring systems. We also outline our proposed next steps in this research.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1109/COMSNETS.2016.7439998' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[W7]</b>&nbsp;<me>Sougata Sen</me>, Kiran K. Rachuri, Abhishek Mukherji, Archan Misra, "<paper>Did you take a break today? Detecting playing foosball using your smartwatch</paper>",  In International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops 2016).<a data-toggle="collapse" href="javascript:toggleDiv('PW7-abstract')">[Abstract]</a><div id='PW7-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Prolonged working hours are a primary cause of stress, work related injuries (e.g, RSIs), and work-life imbalance in employees at a workplace. As reported by some studies, taking timely breaks from continuous work not only reduces stress and exhaustion but also improves productivity, employee bonding, and camaraderie. Our goal is to build a system that automatically detects breaks thereby assisting in maintaining healthy work-break balance. In this paper, we focus on detecting foosball breaks of employees at a workplace using a smartwatch. We selected foosball as it is one of the most commonly played games at many workplaces in the United States. Since playing foosball involves wrist and hand movement, a wrist-worn device (e.g., a smartwatch), due to its position, has a clear advantage over a smartphone for detecting foosball activity. Our evaluation using data collected from real workplace shows that we can identify with more than 95% accuracy whether a person is playing foosball or not. We also show that we can determine how long a foosball session lasted with an error of less than 3% in the best case.</div>&nbsp;<a id="bibTag" href='https://dx.doi.org/10.1109/PERCOMW.2016.7457165' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[W8]</b>&nbsp;<me>Sougata Sen</me>, Vigneshwaran Subbaraju, Archan Misra, Rajesh Krishna Balan, Youngki Lee, "<paper>The case for smartwatch-based diet monitoring</paper>",  In International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops 2015).<img src="images/prize.png" style="width: 25px;align:middle;white-space:nowrap;"><text style='color:red;align:middle;white-space:nowrap;'>[Best Paper Award]</text></img>&nbsp;<a data-toggle="collapse" href="javascript:toggleDiv('PW8-abstract')">[Abstract]</a><div id='PW8-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">We explore the use of gesture recognition on a wrist-worn smartwatch as an enabler of an automated eating activity (and diet monitoring) system. We show, using small-scale user studies, how it is possible to use the accelerometer and gyroscope data from a smartwatch to accurately separate eating episodes from similar non-eating activities, and to additionally identify the mode of eating (i.e., using a spoon, bare hands or chopsticks). Additionally, we investigate the likelihood of automatically triggering the smartwatch's camera to capture clear images of the food being consumed, for possible offline analysis to identify what (and how much) the user is eating. Our results show both the promise and challenges of this vision: while opportune moments for capturing such useful images almost always exist in an eating episode, significant further work is needed to both (a) correctly identify the appropriate instant when the camera should be triggered and (b) reliably identify the type of food via automated analyses of such images.</div>&nbsp;<a id="bibTag" href='http://ieeexplore.ieee.org/document/7134103/' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[W9]</b>&nbsp;<me>Sougata Sen</me>, "<paper>Opportunities and challenges in multi-modal sensing for regular lifestyle tracking</paper>",  In International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops 2015).<a data-toggle="collapse" href="javascript:toggleDiv('PW9-abstract')">[Abstract]</a><div id='PW9-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">With the availability of various publicly available and personal sensors, recording and profiling of activities of daily living (ADL) is becoming a reality. The sensors are omnipresent -in smartphones, smartwatches, and smartglasses and even in the environment around us in the form of peer smartphones or even infrastructure sensors such as bluetooth low energy beacons. However, there are various challenges pertaining to the sensor data processing, which makes creation of activities of daily life tracker challenging. In this work, we discuss about some of these challenges. We also discuss about some ADL tracking systems that we have developed and how we have addressed some of the challenges in building these systems. We further discuss about how various ADL trackers can be combined into a framework which can allow individuals to select a custom set of ADLs for self-tracking.</div>&nbsp;<a id="bibTag" href='http://ieeexplore.ieee.org/document/7134030/' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[W10]</b>&nbsp;<me>Sougata Sen</me>, Archan Misra, Rajesh Balan, Lipyeow Lim, "<paper>The case for cloud-enabled mobile sensing services</paper>",  In Proceedings of MCC workshop on Mobile cloud computing (MCC 2012).<a data-toggle="collapse" href="javascript:toggleDiv('PW10-abstract')">[Abstract]</a><div id='PW10-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">We make the case for cloud-enabled mobile sensing services that support an emerging application class, one which infers near-real time collective context using sensor data obtained continuously from a large set of consumer mobile devices. We present the high-level architecture and functional requirements for such a mobile sensing service, and argue that such a service can significantly improve the scalability and energy-efficiency of large-scale mobile sensing by coordinating the sensing {\&} processing tasks across multiple devices. We then focus specifically on the problem of energy-efficiency and provide early exemplars of how optimizing query execution jointly over multiple phones can lead to substantial energy savings.</div>&nbsp;<a id="bibTag" href='http://dl.acm.org/citation.cfm?doid=2342509.2342521' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR><b>[W11]</b>&nbsp;Kumar Padmanabh, Adi {Malikarjuna V}, <me>Sougata Sen</me>, Siva Prasad Katru, Amrit Kumar, C. {Sai Pawankumar}, Sunil Kumar Vuppala, Sanjoy Paul, "<paper>ISense: A wireless sensor network based conference room management system</paper>",  In Workshop on Embedded Sensing Systems for Energy-Efficiency in Buildings (BuildSys 2009).<a data-toggle="collapse" href="javascript:toggleDiv('PW11-abstract')">[Abstract]</a><div id='PW11-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we have studied the IT system (e.g. MS-outlook) that is used to book meeting rooms in a corporate environment. In the existing IT system, the status of meeting rooms is manually entered, and as a result, it is not reflected in real time in the IT system. This results in severe underutilization of resources (conference rooms) across the corporation, and wastage of electricity with the lights and air-conditioning system being operational even when the rooms are unoccupied. We have created a test bed of motes and analyzed the occupancy and electricity consumption data to estimate the under-utilization of conference rooms, and the wastage of electricity in the process. In order to eliminate these problems, we have designed a wireless sensor network based solution which results in two main benefits: (i) the utilization of the conference room is increased from 67% to 90% and (ii) electricity saving is equivalent to 16000 full grown banyan trees in a year. {\textcopyright} 2010 ACM.</div>&nbsp;<a id="bibTag" href='http://portal.acm.org/citation.cfm?doid=1810279.1810288' style="color:#0074d9;font-weight:normal;" target="_blank">[doi]</a></br><BR></div></div><div class="col-11" id="patents"><div class="clearfix justified"><h2 class="h2 upper">Patents</h2><A id="bibTag">[PT3]</A> Kumar Padmanabh, Puneet Gupta,<Me> Sougata Sen</Me>. <paper>System and method for forming application dependent dynamic data packet in wireless sensor networks</paper> (US Patent 8,588,192)<BR><BR><A id="bibTag">[PT2]</A> Kumar Padmanabh, Adi M. R. Vanteddu, <Me>Sougata Sen</Me>, Amrit Kumar, Puneet Gupta, Lakshya Malhotra, Sunil Vuppala,<paper> Method and system for creating a virtual wireless sensor network</paper> (US Patent 8,649,298)<BR><BR><A id="bibTag">[PT1]</A> <Me> Sougata Sen</Me>, Ketan Patil, Animikh Ghosh, Parag Chauhan, Kumar Padmanabh, <paper>Method and system to dynamically detect and form a master slave network</paper>. (US Patent 8,873,429)</div></div><div class="col-11" id="book"><div class="clearfix justified"><h2 class="h2 upper">Book Chapter</h2><A id="bibTag">[B1]</A> Kumar Padmanabh,<Me> Sougata Sen</Me>, Sanjoy Paul. <paper>ZigBee versus Other Protocols and Standards</paper>. In ZigBee Network Protocols and Applications (pp. 301-344). Auerbach Publications.</div></div></div></div></div></div></div></div></body></html>