
<!-- saved from url=(0039)file:///Users/sougata/Desktop/test.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script src="js/func.js"></script><link  rel="stylesheet" href="css/style_2.0.0.css?v=2.0.2" /> </head><body><A id="bibTag" href='http://doi.acm.org/10.1145/3267305.3267538'>[P1]</a>Varun Mishra, Gunnar Pope, Sarah Lord, Stephanie Lewia, Byron Lowens, Kelly Caine, <me>Sougata Sen</me>, Ryan Halter, David Kotz, "<paper>The Case for a Commodity Hardware Solution for Stress Detection</paper>",  In ACM International Joint Conference and International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers (UbiComp '18 Adjunct).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P1-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P1-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Timely detection of an individual's stress level has the potential to expedite and improve stress management, thereby reducing the risk of adverse health consequences that may arise due to unawareness or mismanagement of stress. Recent advances in wearable sensing have resulted in multiple approaches to detect and monitor stress with varying levels of accuracy. The most accurate methods, however, rely on clinical grade sensors strapped to the user. These sensors measure physiological signals of a person and are often bulky, custom-made, expensive, and/or in limited supply, hence limiting their large-scale adoption by researchers and the general public. In this paper, we explore the viability of commercially available off-the-shelf sensors for stress monitoring. The idea is to be able to use cheap, non-clinical sensors to capture physiological signals, and make inferences about the wearer's stress level based on that data. In this paper, we describe a system involving a popular off-the-shelf heart-rate monitor, the Polar H7; we evaluated our system in a lab setting with three well-validated stress-inducing stimuli with 26 participants. Our analysis shows that using the off-the-shelf sensor alone, we were able to detect stressful events with an F1 score of 0.81, on par with clinical-grade sensors.</div></br><A id="bibTag" href='https://doi.org/10.1109/COMSNETS.2018.8328213'>[P2]</a>Meera Radhakrishnan, <me>Sougata Sen</me>, Archan Misra, Youngki Lee, Rajesh Balan, "<paper>Smart monitoring via participatory BLE relaying</paper>",  In IEEE International Conference on Communication Systems Networks (COMSNETS '18).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P2-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P2-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">We espouse the vision of a smart object/campus architecture where sensors attached to smart objects use BLE as communication interface, and where smartphones act as opportunistic relays to transfer the data. We explore the feasibility of the vision with real-world Wi-Fi based location traces from our university campus. Our feasibility studies establish that redundancy exists in user movement within the indoor spaces, and that this redundancy can be exploited for collecting sensor data in an opportunistic, yet fair manner. We develop a couple of alternative heuristics that address the BLE energy asymmetry challenge by intelligently duty-cycling the scanning actions of individual devices. We evaluate the efficacy and tradeoffs of the proposed approaches by simulation experiments with real-world location traces.</div></br><A id="bibTag" href='http://doi.acm.org/10.1145/3267242.3267259'>[P3]</a><me>Sougata Sen</me>, Archan Misra, Vigneshwaran Subbaraju, Karan Grover, Meera Radhakrishnan, Rajesh K. Balan, Youngki Lee, "<paper>I<sup>4</sup>S: Capturing Shopper's In-store Interactions</paper>",  In ACM International Symposium on Wearable Computers (ISWC '18).<BR><a href='./pdf/i4s2018_slides.pdf'><img src="images/slides.png" style="width: 55px;align:middle;"></a><a data-toggle="collapse" href="javascript:toggleDiv('P3-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P3-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we present I<sup>4</sup>S, a system that identifies item interactions of customers in a retail store through sensor data fusion from smartwatches, smartphones and distributed BLE beacons. To identify these interactions, I<sup>4</sup>S builds a gesture-triggered pipeline that (a) detects the occurrence of" item picks", and (b) performs fine-grained localization of such pickup gestures. By analyzing data collected from 31 shoppers visiting a midsized stationary store, we show that we can identify person-independent picking gestures with a precision of over 88%, and identify the rack from where the pick occurred with 91%+ precision (for popular racks).</div></br><A id="bibTag" href='http://doi.acm.org/10.1145/3264902'>[P4]</a>Shengjie Bi, Tao Wang, Nicole Tobias, Josephine Nordrum, Shang Wang, George Halvorsen, <me>Sougata Sen</me>, Ronald Peterson, Kofi Odame, Kelly Caine, Ryan Halter, Jacob Sorber, David Kotz, "<paper>Auracle: Detecting Eating Episodes with an Ear-mounted Sensor</paper>",  ACM Interact. Mob. Wearable Ubiquitous Technol.. 2(3), 2018.<BR><a data-toggle="collapse" href="javascript:toggleDiv('P4-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P4-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we propose Auracle, a wearable earpiece that can automatically recognize eating behavior. More specifically, in free-living conditions, we can recognize when and for how long a person is eating. Using an off-the-shelf contact microphone placed behind the ear, Auracle captures the sound of a person chewing as it passes through the bone and tissue of the head. This audio data is then processed by a custom analog/digital circuit board. To ensure reliable (yet comfortable) contact between microphone and skin, all hardware components are incorporated into a 3D-printed behind-the-head framework. We collected field data with 14 participants for 32 hours in free-living conditions and additional eating data with 10 participants for 2 hours in a laboratory setting. We achieved accuracy exceeding 92.8% and F1 score exceeding 77.5% for eating detection. Moreover, Auracle successfully detected 20-24 eating episodes (depending on the metrics) out of 26 in free-living conditions. We demonstrate that our custom device could sense, process, and classify audio data in real time. Additionally, we estimate Auracle can last 28.1 hours with a 110 mAh battery while communicating its observations of eating behavior to a smartphone over Bluetooth.</div></br><A id="bibTag" href='https://doi.org/10.1109/WoWMoM.2018.8449755'>[P5]</a><me>Sougata Sen</me>, Vigneshwaran Subbaraju, Archan Misra, Rajesh Balan, Youngki Lee, "<paper>Annapurna: Building a Real-World Smartwatch-Based Automated Food Journal</paper>",  In IEEE International Symposium on A World of Wireless, Mobile and Multimedia Networks (WoWMoM '18).<BR><a href='./pdf/annapurnaWowmom2018_slides.pdf'><img src="images/slides.png" style="width: 55px;align:middle;"></a><a data-toggle="collapse" href="javascript:toggleDiv('P5-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P5-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">We describe the design and implementation of a smartwatch-based, completely unobtrusive, food journaling system, where the smartwatch helps to intelligently capture useful images of food that an individual consumes throughout the day. The overall system, called Annapurna, is based on three key components: (a) a smartwatch-based gesture recognizer to identify eating gestures, (b) a smartwatch-based image capturer that obtains a small set of relevant and useful images with a low energy overhead, and (c) a server-based image filtering engine that removes irrelevant uploaded images, and then catalogs them through a portal. Our primary challenge is to make the system robust to the huge diversity in natural eating habits and food choices. We show how we address this by an appropriate coupling between a smartwatch's camera sensor and inertial sensor-based tracking of eating gestures, thereby helping to capture multiple likely-to-be-useful images with low energy overhead. Through a series of real-world, in-the-wild studies, we demonstrate the end-to-end working of Annapurna, which captures useful images in over 95% of all natural eating episodes.</div></br><A id="bibTag" href='http://www.sciencedirect.com/science/article/pii/S157411921630431X'>[P6]</a>Tianli Mo, Lipyeow Lim, <me>Sougata Sen</me>, Archan Misra, Rajesh Balan, Youngki Lee, "<paper>Cloud-based query evaluation for energy-efficient mobile sensing</paper>",  Pervasive and Mobile Computing. 38(1), 2017.<BR><a data-toggle="collapse" href="javascript:toggleDiv('P6-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P6-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we reduce the energy overheads of continuous mobile sensing, specifically for the case of context-aware applications that are interested in collective context or events, i.e.,¬†events expressed as a set of complex predicates over sensor data from multiple smartphones. We propose a cloud-based query management and optimization framework, called CloQue, that can support thousands of such concurrent queries, executing over a large number of individual smartphones. Our central insight is that the context of different individuals & groups often have significant correlation, and that this correlation can be learned through standard association rule mining on historical data. CloQue‚Äôs¬†exploits such correlation to reduce energy overheads via two key innovations: (i) dynamically reordering the order of predicate processing to preferentially select predicates with not just lower sensing cost and higher selectivity, but that maximally reduce the uncertainty about other context predicates; and (ii) intelligently propagating the query evaluation results to dynamically update the confidence values of other correlated context predicates. We present techniques for probabilistic processing of context queries (to save significant energy at the cost of a query fidelity loss) and for query partitioning (to scale CloQue¬†to a large number of users while meeting latency bounds). An evaluation, using real cellphone traces from two different datasets, shows significant energy savings (between 30% and 50% compared with traditional short-circuit systems) with little loss in accuracy (5% at most). In addition, we utilize parallel evaluation to reduce overall latency. The experiments show our approaches save up to 70% latency.</div></br><A id="bibTag" href='http://doi.acm.org/10.1145/3092305.3092306'>[P7]</a><me>Sougata Sen</me>, Vigneshwaran Subbaraju, Archan Misra, Rajesh Krishna Balan, Youngki Lee, "<paper>Experiences in Building a Real-World Eating Recogniser</paper>",  In ACM International on Workshop on Physical Analytics (WPA '17).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P7-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P7-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we describe the progressive design of the gesture recognition module of an automated food journaling system -- Annapurna. Annapurna runs on a smartwatch and utilises data from the inertial sensors to first identify eating gestures, and then captures food images which are presented to the user in the form of a food journal. We detail the lessons we learnt from multiple in-the-wild studies, and show how eating recognizer is refined to tackle challenges such as (i) high gestural diversity, and (ii) non-eating activities with similar gestural signatures. Annapurna is finally robust (identifying eating across a wide diversity in food content, eating styles and environments) and accurate (false-positive and false-negative rates of 6.5% and 3.3% respectively)</div></br><A id="bibTag" href='http://doi.acm.org/10.1109/PERCOMW.2017.7917646'>[P8]</a><me>Sougata Sen</me>, Karan Grover, Vigneshwaran Subbaraju, Archan Misra, "<paper>Inferring smartphone keypress via smartwatch inertial sensing</paper>",  In IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops '17).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P8-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P8-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Due to numerous benefits, sensor-rich smartwatches and wrist-worn wearable devices are quickly gaining popularity. The popularity of these devices also raises privacy concerns. In this paper we explore one such privacy concern: the possibility of extracting the location of a user's touch-event on a smartphone, using the inertial sensor data of a smartwatch worn by the user on the same arm. This is a major concern not only because it might be possible for an attacker to extract private and sensitive information from the inputs provided but also because the attack mode utilises a device (smartwatch) that is distinct from the device being attacked (smartphone). Through a user study we find that such attacks are possible. Specifically, we can infer the user's entry pattern on a qwerty keyboard, with an error bound of ±2 neighboring keys, with 73.85% accuracy. As a possible preventive mechanism, we also show that adding a little white noise to inertial sensor data can reduce the inference accuracy by almost 30%, without affecting the accuracy of macro-gesture recognition.</div></br><A id="bibTag" href='https://doi.org/10.1109/COMSNETS.2016.7439946'>[P9]</a>Meera Radhakrishnan, <me>Sougata Sen</me>, Archan Misra, Rajesh Balan, "<paper>IoT+Small Data: Transforming in-store shopping analytics amp; services</paper>",  In IEEE International Conference on Communication Systems and Networks (COMSNETS '16).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P9-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P9-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">We espouse a vision of small data-based immersive retail analytics, where a combination of sensor data, from personal wearable-devices and store-deployed sensors & IoT devices, is used to create real-time, individualized services for in-store shoppers. Key challenges include (a) appropriate joint mining of sensor & wearable data to capture a shopper's product-level interactions, and (b) judicious triggering of power-hungry wearable sensors (e.g., camera) to capture only relevant portions of a shopper's in-store activities. To explore the feasibility of our vision, we conducted experiments with 5 smartwatch-wearing users who interacted with objects placed on cupboard racks in our lab (to crudely mimic corresponding grocery store interactions). Initial results show significant promise: 94% accuracy in identifying an item-picking gesture, 85% accuracy in identifying the shelf-location from where the item was picked and 61% accuracy in identifying the exact item picked (via analysis of the smartwatch camera data).</div></br><A id="bibTag" href='http://ieeexplore.ieee.org/abstract/document/7457165/'>[P10]</a><me>Sougata Sen</me>, Kiran Rachuri, Abhishek Mukherji, Archan Misra, "<paper>Did you take a break today? Detecting playing foosball using your smartwatch</paper>",  In IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops '16).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P10-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P10-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Prolonged working hours are a primary cause of stress, work related injuries (e.g, RSIs), and work-life imbalance in employees at a workplace. As reported by some studies, taking timely breaks from continuous work not only reduces stress and exhaustion but also improves productivity, employee bonding, and camaraderie. Our goal is to build a system that automatically detects breaks thereby assisting in maintaining healthy work-break balance. In this paper, we focus on detecting foosball breaks of employees at a workplace using a smartwatch. We selected foosball as it is one of the most commonly played games at many workplaces in the United States. Since playing foosball involves wrist and hand movement, a wrist-worn device (e.g., a smartwatch), due to its position, has a clear advantage over a smartphone for detecting foosball activity. Our evaluation using data collected from real workplace shows that we can identify with more than 95% accuracy whether a person is playing foosball or not. We also show that we can determine how long a foosball session lasted with an error of less than 3% in the best case.</div></br><A id="bibTag" href='https://ieeexplore.ieee.org/document/7676201'>[P11]</a>Mateusz Mikusz, Sarah Clinch, <me>Sougata Sen</me>, "<paper>MobiSys 2016</paper>",  IEEE Pervasive Computing. 15(4), 2016.<BR><a data-toggle="collapse" href="javascript:toggleDiv('P11-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P11-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">The 14th ACM International Conference on Mobile Systems, Applications, and Services (MobiSys 2016) spanned a range of themes and domains, from smart environments to security and privacy. The highlights presented here cover the keynotes, paper sessions, and first Asian Students Symposium on Emerging Technologies.</div></br><A id="bibTag" href='https://ieeexplore.ieee.org/abstract/document/7439998'>[P12]</a><me>Sougata Sen</me>, "<paper>Pervasive physical analytics using multi-modal sensing</paper>",  In IEEE International Conference on Communication Systems and Networks (COMSNETS '16).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P12-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P12-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">With the gradual increase in the number of individually owned mobile and wearable devices, as well as increase in the number of publicly available sensing devices, automatic & unobtrusive monitoring of Activities of Daily Living (ADLs) is gradually becoming possible. In this work, we discuss about the important trade-off between energy, accuracy and non-personalization that has to be considered while building commercially successful ADL monitoring systems. We then describe two ADL monitoring systems that we have built which addresses technical challenges pertaining to building ADL monitoring systems. We also outline our proposed next steps in this research.</div></br><A id="bibTag" href='https://ieeexplore.ieee.org/abstract/document/7134103'>[P13]</a><me>Sougata Sen</me>, Vigneshwaran Subbaraju, Archan Misra, Rajesh Balan, Youngki Lee, "<paper>The case for smartwatch-based diet monitoring</paper>",  In IEEE International Conference on Pervasive Computing and Communication Workshops  (PerCom Workshops '15).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P13-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P13-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">We explore the use of gesture recognition on a wrist-worn smartwatch as an enabler of an automated eating activity (and diet monitoring) system. We show, using small-scale user studies, how it is possible to use the accelerometer and gyroscope data from a smartwatch to accurately separate eating episodes from similar non-eating activities, and to additionally identify the mode of eating (i.e., using a spoon, bare hands or chopsticks). Additionally, we investigate the likelihood of automatically triggering the smartwatch's camera to capture clear images of the food being consumed, for possible offline analysis to identify what (and how much) the user is eating. Our results show both the promise and challenges of this vision: while opportune moments for capturing such useful images almost always exist in an eating episode, significant further work is needed to both (a) correctly identify the appropriate instant when the camera should be triggered and (b) reliably identify the type of food via automated analyses of such images.</div></br><A id="bibTag" href='https://ieeexplore.ieee.org/abstract/document/7146513'>[P14]</a>Subbaraju Vigneshwaran, <me>Sougata Sen</me>, Archan Misra, Satyadip Chakraborti, Rajesh Balan, "<paper>Using infrastructure-provided context filters for efficient fine-grained activity sensing</paper>",  In IEEE International Conference on Pervasive Computing and Communications (PerCom '15').<BR><a data-toggle="collapse" href="javascript:toggleDiv('P14-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P14-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">While mobile and wearable sensing can capture unique insights into fine-grained activities (such as gestures and limb-based actions) at an individual level, their energy overheads are still prohibitive enough to prevent them from being executed continuously. In this paper, we explore practical alternatives to addressing this challenge-by exploring how cheap infrastructure sensors or information sources (e.g., BLE beacons) can be harnessed with such mobile/wearable sensors to provide an effective solution that reduces energy consumption without sacrificing accuracy. The key idea is that many fine-grained activities that we desire to capture are specific to certain location, movement or background context: infrastructure sensors and information sources (e.g., BLE beacons) offer practical and cheap ways to identify such context. In this paper, we first explore how various infrastructure, mobile & wearable sensors can be used to identify fine-grained location/movement context (e.g., transiting through a door). We then show, using a couple of illustrative examples (specifically, the detection of `switch pressing' before exiting a room and the identification of `water drinking' after approaching a water cooler) to show that such background context can be predicted, with sufficient accuracy, with sufficient lead time to enable a `triggered' model for mobile/wearable sensing of such microscopic, transient gestures and activities. Moreover, such `triggered' sensing also helps to improve the accuracy of such microscopic gesture recognition, by reducing the set of candidate activity labels. Empirical experiments show that we are able to identify 82.2% of switch-pressing and 91.73% of water-drinking activities in a campus lab setting, with a significant reduction in active sensing time (up to 92.9% compared to continuous sensing).</div></br><A id="bibTag" href='https://ieeexplore.ieee.org/abstract/document/7134030'>[P15]</a><me>Sougata Sen</me>, "<paper>Opportunities and challenges in multi-modal sensing for regular lifestyle tracking</paper>",  In IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops '15).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P15-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P15-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">With the availability of various publicly available and personal sensors, recording and profiling of activities of daily living (ADL) is becoming a reality. The sensors are omnipresent - in smartphones, smartwatches, and smartglasses and even in the environment around us in the form of peer smartphones or even infrastructure sensors such as bluetooth low energy beacons. However, there are various challenges pertaining to the sensor data processing, which makes creation of activities of daily life tracker challenging. In this work, we discuss about some of these challenges. We also discuss about some ADL tracking systems that we have developed and how we have addressed some of the challenges in building these systems. We further discuss about how various ADL trackers can be combined into a framework which can allow individuals to select a custom set of ADLs for self-tracking.</div></br><A id="bibTag" href='https://ieeexplore.ieee.org/abstract/document/6799058'>[P16]</a><me>Sougata Sen</me>, Kartik Muralidharan, "<paper>Putting ‘pressure’ on mobile authentication</paper>",  In IEEE International Conference on Mobile Computing and Ubiquitous Networking (ICMU'14).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P16-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P16-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Using a 4 digit passcode as authentication is popular among most smartphone users. However, this type of authentication is highly susceptible to a brute force or shoulder surfing attack. Further, it is not uncommon for close family members or friends to already be aware of this secret passcode. The key limitation of such an approach is that it is solely dependent on `what a user knows'. We present an authentication mechanism that overcomes this limitation by including an additional factor of `what a user is'. In our scheme, in addition to knowing the passcode, we capture the behaviour in which the passcode is entered. We model this behaviour in terms of the pressure applied on the screen by the user as well the duration the screen is pressed for. A key challenge of this approach is to ensure security without forgoing usability. This is particularly hard given the constraints of mobile computing. We tested our authentication mechanism through a user study of 10 participants and initial results show that our approach is both secure and usable.</div></br><A id="bibTag" href='http://doi.acm.org/10.1145/2634317.2634338'>[P17]</a><me>Sougata Sen</me>, Dipanjan Chakraborty, Vigneshwaran Subbaraju, Dipyaman Banerjee, Archan Misra, Nilanjan Banerjee, Sumit Mittal, "<paper>Accommodating User Diversity for In-store Shopping Behavior Recognition</paper>",  In ACM International Symposium on Wearable Computers (ISWC '14).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P17-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P17-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">This paper explores the possibility of using mobile sensing data to detect certain in-store shopping intentions or behaviours of shoppers. We propose a person-independent activity recognition technique called CROSDAC, which captures the diversity in the manifestation of such intentions or behaviours in a heterogeneous set of users in a data-driven manner via a 2-stage clustering-cum-classification technique. Using smartphone based sensor data (accelerometer, compass and Wi-Fi) from a directed, but real-life study involving 86 shopping episodes from 30 users in a mall's food court, we show that CROSDAC's mobile sensing-based approach can offer reasonably high accuracy (77:6% for a 2-class identification problem) and outperforms the traditional community-driven approaches that unquestioningly segment users on the basis of underlying demographic or lifestyle attributes.</div></br><A id="bibTag" href='https://doi.org/10.1109/MDM.2014.33'>[P18]</a>Tianli Mo, <me>Sougata Sen</me>, Lipyeow Lim, Archan Misra, Rajesh Balan, Youngki Lee, "<paper>Cloud-Based Query Evaluation for Energy-Efficient Mobile Sensing</paper>",  In 2014 IEEE 15th International Conference on Mobile Data Management (MDM'14).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P18-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P18-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we reduce the energy overheads of continuous mobile sensing for context-aware applications that are interested in collective context or events. We propose a cloud-based query management and optimization framework, called CloQue, which can support concurrent queries, executing over thousands of individual smartphones. CloQue exploits correlation across context of different users to reduce energy overheads via two key innovations: i) Dynamically reordering the order of predicate processing to preferentially select predicates with not just lower sensing cost and higher selectivity, but that maximally reduce the uncertainty about other context predicates, and ii) intelligently propagating the query evaluation results to dynamically update the uncertainty of other correlated, but yet-to-be evaluated, context predicates. An evaluation, using real cell phone traces from a real world dataset shows significant energy savings (between 30 to 50% compared with traditional short-circuit systems) with little loss in accuracy (5% at most).</div></br><A id="bibTag" href='http://doi.acm.org/10.1145/2342509.2342521'>[P19]</a><me>Sougata Sen</me>, Archan Misra, Rajesh Balan, Lipyeow Lim, "<paper>The Case for Cloud-enabled Mobile Sensing Services</paper>",  In ACM Workshop on Mobile Cloud Computing (MCC '12).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P19-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P19-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">We make the case for cloud-enabled mobile sensing services that support an emerging application class, one which infers near-real time collective context using sensor data obtained continuously from a large set of consumer mobile devices. We present the high-level architecture and functional requirements for such a mobile sensing service, and argue that such a service can significantly improve the scalability and energy-efficiency of large-scale mobile sensing by coordinating the sensing & processing tasks across multiple devices. We then focus specifically on the problem of energy-efficiency and provide early exemplars of how optimizing query execution jointly over multiple phones can lead to substantial energy savings.</div></br><A id="bibTag" href='http://doi.acm.org/10.1145/1810279.1810288'>[P20]</a>Kumar Padmanabh, V Malikarjuna, <me>Sougata Sen</me>, Siva Prasad Katru, Amrit Kumar, Sai Pawankumar C, Sunil Kumar Vuppala, Sanjoy Paul, "<paper>iSense: A Wireless Sensor Network Based Conference Room Management System</paper>",  In ACM Workshop on Embedded Sensing Systems for Energy-Efficiency in Buildings (BuildSys '09).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P20-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P20-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">In this paper, we have studied the IT system (e.g. MS-outlook) that is used to book meeting rooms in a corporate environment. In the existing IT system, the status of meeting rooms is manually entered, and as a result, it is not reflected in real time in the IT system. This results in severe underutilization of resources (conference rooms) across the corporation, and wastage of electricity with the lights and air-conditioning system being operational even when the rooms are unoccupied. We have created a test bed of motes and analyzed the occupancy and electricity consumption data to estimate the under-utilization of conference rooms, and the wastage of electricity in the process. In order to eliminate these problems, we have designed a wireless sensor network based solution which results in two main benefits: (i) the utilization of the conference room is increased from 67% to 90% and (ii) electricity saving is equivalent to 16000 full grown banyan trees in a year.</div></br><A id="bibTag" href='https://ieeexplore.ieee.org/abstract/document/4475745'>[P21]</a>Kumar Padmanabh, Adi Reddy, <me>Sougata Sen</me>, Puneet Gupta, "<paper>Random Walk on Random Graph based Outlier Detection in Wireless Sensor Networks</paper>",  In IEEE International Conference on Wireless Communication and Sensor Networks (WCSN '07).<BR><a data-toggle="collapse" href="javascript:toggleDiv('P21-abstract')"><img src="images/abstract.png" style="width: 75px;align:middle;"></a><div id='P21-abstract' class='abstract' style="display:none;margin:0 2.5% 0 2.5%;padding:0 2.5% 0 2.5%">Wireless Sensor Network (WSN) is characterized with limited battery power and limited computation capability. Sensor nodes which produce a data set that is different from their counter parts are called Outlier nodes. For example, in a particular room, if we expect temperature of 25degC and if we receive a temperature reading of 73degC. This is called outlier data and the node which produces this data is called outliers nodes. We are considering a system where user is interested only in outlier data. We assumed that outlier data is generated due to the ambiance parameter. We also assumed that instead of sending all the sensed data, nodes are required to send the outlier data in response to a query from the base station. In this paper we found that using traditional routing protocol for communications is not an optimum solution. Traditional routing protocols consume more memory and battery power in the route-request process. We have also suggested that use of "Random Walk on Random Graph Technique" reduces the overhead of transmitting packets. We have proved this with analysis and simulation. We argue that with random walk on random graph mechanism, energy consumption is minimized and numbers of packets flooded in the network is very less.</div></br></body></html>